{
  
    
        "post0": {
            "title": "Title",
            "content": "install surf2stl-python . !git clone https://github.com/asahidari/surf2stl-python . Cloning into &#39;surf2stl-python&#39;... remote: Enumerating objects: 19, done. remote: Counting objects: 100% (19/19), done. remote: Compressing objects: 100% (16/16), done. remote: Total 19 (delta 4), reused 17 (delta 2), pack-reused 0 Unpacking objects: 100% (19/19), done. . cd surf2stl-python . /content/surf2stl-python . How to draw CalbiYau Manifold . $$ z^n_1 + z^n_2 = 1 $$parameter$ z_1, z_2$ is defined below . $$ z_1= e^{iφ}[cos(x + iy)]^ frac2{n} $$$$ z_2= e^{iφ}[sin (x + iy)]^ frac2{n} $$$$ φ_1= frac{2πk_1}{n} (0 ≦ k &lt; n) $$$$ φ_2= frac{2πk_1}{n} (0 ≦ k &lt; n) $$ . Parameter k1 and k2 individually take Integer values from 0 to n - 1, and results in n x n parts of the manifold(manupulate x, y each pattern in $nxn=n^2$) . | to visualize Calabi-Yau manifold means that to satisfy equation $z^n_1 + z^n_2 = 1$ ,then we can get z1, z2 by moving parameter x,y and integer k1, k2 . | $z_1, z_2$ spread 4Dimention thinking considering real number&amp;imaginary number($Re(z_1),Im(z_1),Re(z_2),Im(z_2)$ ), so we should think to reduce dimention | reduce $Im(z_1),Im(z_2)$ then make $(Re(z1),Re(z2),Im(z1)cos(a)+Im(z2)sin(a))$ 3D | . Import library . import numpy as np import math, cmath # cmath: 複素数のためのライブラリ import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D import matplotlib.ticker as plticker from matplotlib import cm from scipy.spatial import Delaunay import surf2stl as s2s . Set Parameter . N = 9 # Dimension a = 0.4 row, col = 30, 30 writeSTL = False . define function for caculation . def calcZ1(x, y, k, n): return cmath.exp(1j*(2*cmath.pi*k/n)) * (cmath.cos(x+y*1j)**(2/n)) def calcZ2(x, y, k, n): return cmath.exp(1j*(2*cmath.pi*k/n)) * (cmath.sin(x+y*1j)**(2/n)) def calcZ1Real(x, y, k, n): return (calcZ1(x, y, k, n)).real def calcZ2Real(x, y, k, n): return (calcZ2(x, y, k, n)).real def calcZ(x, y, k1_, k2_, n, a_): z1 = calcZ1(x, y, k1, n) z2 = calcZ2(x, y, k2, n) return z1.imag * math.cos(a_) + z2.imag*math.sin(a_) . Draw . x = np.linspace(0, math.pi/2, col) y = np.linspace(-math.pi/2, math.pi/2, row) x, y = np.meshgrid(x, y) # init graph fig = plt.figure(figsize=(18,8)) for n in range(2, N): ax = fig.add_subplot(2, 4, n - 1, projection=&#39;3d&#39;) ax.view_init(elev=15, azim=15) ax.set_title(&quot;n=%d&quot; % n) ax.set_xlabel(&#39;X&#39;) ax.set_ylabel(&#39;Y&#39;) loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals ax.xaxis.set_major_locator(loc) ax.yaxis.set_major_locator(loc) ax.zaxis.set_major_locator(loc) count = 0 for k1 in range(n): for k2 in range(n): # calc X, Y, Z values X = np.frompyfunc(calcZ1Real, 4, 1)(x, y, k1, n).astype(&#39;float32&#39;) Y = np.frompyfunc(calcZ2Real, 4, 1)(x, y, k2, n).astype(&#39;float32&#39;) Z = np.frompyfunc(calcZ, 6, 1)(x, y, k1, k2, n, a).astype(&#39;float32&#39;) ax.plot_surface(X, Y, Z, cmap=cm.ocean, linewidth=0) . Reference . Creating Calabi Yau Manifold in python | Calabi-Yau多様体をブラウザ上に可視化する | .",
            "url": "https://interkid.github.io/My_Research/2021/10/26/CreatingCalabiYauManifold.html",
            "relUrl": "/2021/10/26/CreatingCalabiYauManifold.html",
            "date": " • Oct 26, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "NewworkXによる可視化/分析",
            "content": "&#30446;&#27425; . 基本 | 密度とクラスタ係数 | スモールワールド生成 | 次数と次数分布 | スケールフリー作成 | 距離と直径 | 中心性 | . NetworkXでできること . ネットワークグラフ作成のコードによる簡単な生成 グラフのビジュアルはシンプル(綺麗なレベルではない) | . | ネットワーク分析の文脈での用途が多い ex. 中心人物(ハブ)を見つけて感染制御, グループを抽出して、推薦システム など | . | . この記事の参考はほぼこちら引用🙏 https://www.youtube.com/watch?v=AC4u1PYlveU | 公式ref https://networkx.org/documentation/stable/reference/index.html | . &#22522;&#26412; . import networkx as nx # NetworkXをインポート import matplotlib.pyplot as plt import numpy as np . G = nx.Graph([(1, 2), (2, 3), (3, 1)]) # G = nx.Graph() # 空のグラフを作成する場合 nx.draw(G, with_labels=True,font_family=&#39;sans-serif&#39;) # ラベルをTrueにして番号の可視化 . 数字以外の日本語,文字の記述も設定を加えれば可能(defaultで文字化けする) | . G.add_node(4) # 4は繋がってないので遠くに配置 nx.draw(G, with_labels=True) . G.add_edge(1,4) nx.draw(G, with_labels=True) . n = [5, 6, 7] G.add_nodes_from(n) # 複数リンクの追加 e = [(5,6), (3,7), (4,6)] G.add_edges_from(e) nx.draw(G, with_labels=True) . G.remove_node(4) nx.draw(G, with_labels=True) . G.remove_edges_from([(1,2), (2,3)]) nx.draw(G, with_labels=True) . rnd = nx.gnp_random_graph(10, 0.5) # (第1引数　ノードの数, 第２引数　エッジを引く確率(1で全て引く)) pos=nx.circular_layout(rnd) # 円周上に等間隔で配置 #pos = nx.spring_layout(rnd) # バネモデル(繋がり(バネ)が自然の長さ) #pos = nx.random_layout(rnd) #ランダムなレイアウト plt.title(&#39;random graph&#39;) nx.draw(rnd, pos, with_labels=True) . K_10 = nx.complete_graph(10) pos=nx.spring_layout(K_10) plt.title(&#39;complete graph&#39;) nx.draw(K_10, pos, with_labels=True) . star = nx.star_graph(100) pos=nx.spring_layout(star) plt.title(&#39;star graph&#39;) nx.draw(star, pos, with_labels=True) . wheel = nx.wheel_graph(10) pos=nx.spring_layout(wheel) plt.title(&#39;wheel graph&#39;) nx.draw(wheel, pos, with_labels=True) . &#23494;&#24230;&#12392;&#12463;&#12521;&#12473;&#12479;&#20418;&#25968; . 密度: どれだけネットワークが密集しているか . 密度を求める式 $$ density = リンクの総数 / ノードのペアの総数 = frac{m}{n(n-1) -2} $$ . %matplotlib inline import networkx as nx # NetworkXをインポート import matplotlib.pyplot as plt import numpy as np # ネットワーク生成 G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (3, 4), (4,5), (4,6),(5,6)]) nx.draw(G, with_labels=True) # ラベルをTrueにして番号の可視化 . クラスタ係数 : 隣接ノード同士がどのくらい繋がっているか (数値化の数式は省略) . print(nx.average_clustering(G)) . 0.5833333333333334 . %matplotlib inline import networkx as nx # NetworkXをインポート import matplotlib.pyplot as plt import numpy as np # ランダムグラフ生成 rnd = nx.gnp_random_graph(10, 0.1) #pos=nx.spring_layout(rnd) pos=nx.circular_layout(rnd) #pos = nx.random_layout(rnd) plt.title(&#39;random graph&#39;) nx.draw(rnd, pos, with_labels=True) print(&#39;density:&#39;, nx.density(rnd), &#39;, clustering coefficient:&#39;, nx.average_clustering(rnd)) . density: 0.044444444444444446 , clustering coefficient: 0.0 . cycle = nx.cycle_graph(10) pos=nx.spring_layout(cycle) #pos=nx.circular_layout(cycle) #pos=nx.random_layout(cycle) plt.title(&#39;cycle graph&#39;) nx.draw(cycle, pos, with_labels=True) print(&#39;density:&#39;, nx.density(cycle), &#39;, clustering coefficient:&#39;, nx.average_clustering(cycle)) . density: 0.2222222222222222 , clustering coefficient: 0.0 . K_10 = nx.complete_graph(10) pos=nx.spring_layout(K_10) plt.title(&#39;complete graph&#39;) nx.draw(K_10, pos, with_labels=True) print(&#39;density:&#39;, nx.density(K_10), &#39;, clustering coefficient:&#39;, nx.average_clustering(K_10)) . density: 1.0 , clustering coefficient: 1.0 . &#12473;&#12514;&#12540;&#12523;&#12527;&#12540;&#12523;&#12489;&#12493;&#12483;&#12488;&#12527;&#12540;&#12463;&#29983;&#25104; . 経路長が長い&amp; 高度にクラスタ化を兼ね備えたネットワーク . n = 100 # ノード数 k = 4 # 次数 p = 0.1 # リンクつなぎ替え確率 print(&#39;NetworkXのwatts_strogatz_graph()より生成&#39;) G1 = nx.watts_strogatz_graph(n, k, p) pos = nx.circular_layout(G1) print(nx.info(G1)) # 種々の情報を出力 print(&#39;クラスタ係数：&#39;, nx.average_clustering(G1)) # ネットワーク全体のクラスタ係数を出力 nx.draw(G1, pos) plt.show() . NetworkXのwatts_strogatz_graph()より生成 Graph with 100 nodes and 200 edges クラスタ係数： 0.42566666666666664 . def gen_WS_network(n, k, p, seed=None): if seed is not None: np.random.seed(seed=seed) G = nx.Graph() G.add_nodes_from(list(range(n))) for i in range(n): for j in range(k//2): G.add_edge(i, (i+j+1)%n) # k/2本リンクを張る for (u,v) in G.edges(): if np.random.rand() &lt; p: # pの確率でつなぎ替え G.remove_edge(u, v) new_node = (u+np.random.randint(n-1)+1)%n # 新しい接続先としてu+1からu-1までの中からランダムに選ぶ while G.has_edge(u, new_node) == True: # 既存リンクは除外 new_node = (u+np.random.randint(n-1)+1)%n G.add_edge(u, new_node) return G . n = 100 k = 4 p = 0.1 print(&#39;自作関数による生成&#39;) G2 = gen_WS_network(n, k, p) pos = nx.circular_layout(G2) print(nx.info(G2)) print(&#39;クラスタ係数：&#39;, nx.average_clustering(G2)) nx.draw(G2, pos) plt.show() . 自作関数による生成 Graph with 100 nodes and 200 edges クラスタ係数： 0.3556190476190476 . &#27425;&#25968;&#12392;&#27425;&#25968;&#20998;&#24067; . 次数: ノード(頂点)が持つリンク（辺)の数 平均次数: 次数kの平均値 次数分布: 次数が全ノードに占める割合: p(k) 棒グラフで表すことが多い . G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (4,5)]) print(nx.info(G)) print(G.nodes()) nx.draw(G, with_labels=True) # ラベルをTrueにして番号の可視化 . Graph with 5 nodes and 5 edges [1, 2, 3, 4, 5] . print(nx.degree_histogram(G)) # 時数の個数を出力 degree_dist = [i/5 for i in nx.degree_histogram(G)] plt.rcParams[&#39;font.size&#39;] = 20 plt.bar(range(5), height = degree_dist) # 時数の割合ヒストグラムを出力 plt.xlabel(&#39;$k$&#39;) plt.ylabel(&#39;$p(k)$&#39;) plt.ylim(0,1) . [0, 2, 2, 0, 1] . (0.0, 1.0) . &#12473;&#12465;&#12540;&#12523;&#12501;&#12522;&#12540;&#12493;&#12483;&#12488;&#12527;&#12540;&#12463; . 多数が少数とつながり、少数が多数とつながっているスケールフリーネットワーク(BAモデルを使う) ex WWW, 俳優の共演関係 時数分布はべき則となる 参考: https://syodokukai.exblog.jp/20771928/ . n = 100 m = 4 print(&#39;NetworkX.barabasi_albert_graph()&#39;) G1 = nx.barabasi_albert_graph(n, m) print(nx.info(G1)) nx.draw(G1) plt.show() . NetworkX.barabasi_albert_graph() Graph with 100 nodes and 384 edges . n = 5000 m = 4 # スケールフリーネットワークの生成 G = nx.barabasi_albert_graph(n, m) # 組み込み関数で生成 # G = gen_BA_network(n, m) # 自作関数で生成 k = [i for i,x in enumerate(nx.degree_histogram(G)) if x != 0] degree_dist = [i/n for i in nx.degree_histogram(G) if i != 0] print(k) print(degree_dist) plt.xscale(&#39;log&#39;) plt.yscale(&#39;log&#39;) plt.ylim(0.0001,1) plt.scatter(k, degree_dist) . [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 62, 63, 65, 67, 72, 73, 74, 75, 76, 77, 81, 85, 87, 93, 94, 96, 97, 102, 107, 114, 115, 120, 122, 128, 201, 248, 267] [0.3324, 0.1938, 0.1154, 0.0776, 0.0542, 0.0396, 0.0308, 0.0254, 0.0188, 0.0152, 0.0118, 0.0106, 0.008, 0.007, 0.0056, 0.0048, 0.0052, 0.0034, 0.0038, 0.0024, 0.0028, 0.0014, 0.0018, 0.0012, 0.0022, 0.0016, 0.0018, 0.0012, 0.001, 0.0012, 0.0008, 0.0012, 0.0012, 0.0008, 0.0002, 0.001, 0.0006, 0.0012, 0.0002, 0.0004, 0.0006, 0.0004, 0.0004, 0.0002, 0.0004, 0.0006, 0.0004, 0.0004, 0.0004, 0.0002, 0.0002, 0.0002, 0.0004, 0.0002, 0.0002, 0.0004, 0.0004, 0.0002, 0.0002, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002] . &lt;matplotlib.collections.PathCollection at 0x7f1c8bddf050&gt; . &#36317;&#38626; . 距離: ノードペア間の最短経路の長さ | 平均距離: 全ペアの距離の平均値 | 直径: 全ペアの距離の中で最大のもの | . G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (3, 4), (4,5), (4,6),(5,6)]) nx.draw(G, with_labels=True) # ラベルをTrueにして番号の可視化 . print(nx.shortest_path_length(G, 1, 2)) print(nx.shortest_path_length(G, 3, 6)) . 1 2 . print(nx.shortest_path(G, 1, 2)) print(nx.shortest_path(G, 2, 6)) print([p for p in nx.all_shortest_paths(G, 2, 6)]) . [1, 2] [2, 1, 4, 6] [[2, 1, 4, 6], [2, 1, 5, 6]] . print(&#39;L=&#39;, nx.average_shortest_path_length(G)) print(&#39;D=&#39;, nx.diameter(G)) . L= 1.5333333333333334 D= 3 . &#20013;&#24515;&#24615;(Centrality) . &quot;中心&quot;の指標 . 次数中心性: 次数(ノードが持つリンクの数)で決める / 正規化した値を算出 | 近接中心性: 他の全て他の全てのノードへの距離(最短経路長)の平均値の逆数 | 他にも指標あり | . 活用: snsの中心性など . G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (3, 4), (4,5), (4,6),(5,6)]) nx.draw(G, with_labels=True) # ラベルをTrueにして番号の可視化 print(&#39;Degree Centrality&#39;, nx.degree_centrality(G)) # 次数中心性 print(&#39;Closeness Centrality&#39;, nx.closeness_centrality(G)) # 近接中心性 . Degree Centrality {1: 0.8, 2: 0.2, 3: 0.4, 4: 0.8, 5: 0.6000000000000001, 6: 0.4} Closeness Centrality {1: 0.8333333333333334, 2: 0.5, 3: 0.625, 4: 0.8333333333333334, 5: 0.7142857142857143, 6: 0.5555555555555556} .",
            "url": "https://interkid.github.io/My_Research/2021/10/20/NetworkVisualization.html",
            "relUrl": "/2021/10/20/NetworkVisualization.html",
            "date": " • Oct 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "LSTM Algorithm & Implementation",
            "content": "Algorithm . Long-term-short-memory . . . TIme Series Analysis . purpose . Description | Modeling .. inference model and grasp feature time series | Prediction | Control .. manipulate variables to fluctuate purpose variable | TIme Series Analysis in RNN . RNN dose&#39;nt require prior knowledge for modeling trends &amp; period is learned from data autmatically | . | RNN weaksness when prediction of stock if there are only 3 years data, RNN can&#39;t perform well | . | . . Compare for methods in Time Series Forecasting . RNN(LSTM) is more expressionable in terms of function (but Blackbox) . Implementaion (pytorch) . Model Define . import torch import torch.nn as nn . input_dim = 5 # e.g. input of dimension 5 will look like this [1, 3, 8, 2, 3] hidden_dim = 10 # if the hidden dimension is 3 [3, 5, 4] n_layers = 1 # the number of LSTM layers stacked lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True) . Input Data . batch_size = 1 seq_len = 1 # initialize input, hidden state, cell state(long_memory) inp = torch.randn(batch_size, seq_len, input_dim) hidden_state = torch.randn(n_layers, batch_size, hidden_dim) cell_state = torch.randn(n_layers, batch_size, hidden_dim) hidden = (hidden_state, cell_state) print(&quot;inp_size: {}, n hidden_state_size: {}, n cell_state_size: {}&quot;.format(inp.shape, hidden_state.shape, cell_state.shape)) hidden . inp_size: torch.Size([1, 1, 5]), hidden_state_size: torch.Size([1, 1, 10]), cell_state_size: torch.Size([1, 1, 10]) . (tensor([[[ 2.7525, -0.3706, -0.1003, -0.8155, 0.1962, 1.3871, 0.4509, 0.3741, 0.4785, -0.6127]]]), tensor([[[ 1.1783, -0.6752, -1.6241, 0.0391, -1.1110, -0.5538, -1.5670, 0.1072, 0.0810, -0.4173]]])) . out, hidden = lstm_layer(inp, hidden) print(&quot;Outout shape:&quot;, out.shape) print(&quot;Hiden&quot;, hidden) . Outout shape: torch.Size([1, 1, 10]) Hiden (tensor([[[ 0.1804, -0.1010, -0.3767, -0.0170, -0.0909, 0.0929, -0.4508, 0.0109, 0.1320, -0.1107]]], grad_fn=&lt;StackBackward&gt;), tensor([[[ 0.2725, -0.1367, -0.8260, -0.0767, -0.1377, 0.2064, -1.0127, 0.0231, 0.2400, -0.1765]]], grad_fn=&lt;StackBackward&gt;)) . .. LSTM cell process the input and hidden states at each time step . seq_len = 3 inp = torch.randn(batch_size, seq_len, input_dim) out, hidden = lstm_layer(inp, hidden) print(out.shape) . torch.Size([1, 3, 10]) . .. the output&#39;s 2nd dimension is 3, indicating that there were 3 outputs given by the LSTM. This corresponds to the length of our input sequence. . Reference . viya-recurrent-neural-network.pdf | Long Short-Term Memory: From Zero to Hero with PyTorch | .",
            "url": "https://interkid.github.io/My_Research/2021/10/09/LSTM_introduction.html",
            "relUrl": "/2021/10/09/LSTM_introduction.html",
            "date": " • Oct 9, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "KNN Algorithm",
            "content": "KNN: What&#39;s it for . simple classification or regeression algorithm simple = low accuracy rather than other Algorithm | . | Regression Find the K closest points to a sample point and return the average value | . | . . The KNN&#8217;s steps are: . Receive an unclassified data; | Measure the distance (Euclidian, Manhattan, Minkowski or Weighted) from the new data to all others data that is already classified; | Gets the K(K is a parameter that you difine) smaller distances; | Check the list of classes had the shortest distance and count the amount of each class that appears; | Takes as correct class the class that appeared the most times; | Classifies the new data with the class that you took in step 5; | How is it used? . Dimensionality reduction stage Avoid sparse data | . | . Implementation Iris dataset . import numpy as np import matplotlib.pyplot as plt import pandas as pd . Data . url = &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&quot; names = [&#39;sepal-length&#39;, &#39;sepal-width&#39;, &#39;petal-length&#39;, &#39;petal-width&#39;, &#39;Class&#39;] dataset = pd.read_csv(url, names=names) . dataset . sepal-length sepal-width petal-length petal-width Class . 0 5.1 | 3.5 | 1.4 | 0.2 | Iris-setosa | . 1 4.9 | 3.0 | 1.4 | 0.2 | Iris-setosa | . 2 4.7 | 3.2 | 1.3 | 0.2 | Iris-setosa | . 3 4.6 | 3.1 | 1.5 | 0.2 | Iris-setosa | . 4 5.0 | 3.6 | 1.4 | 0.2 | Iris-setosa | . ... ... | ... | ... | ... | ... | . 145 6.7 | 3.0 | 5.2 | 2.3 | Iris-virginica | . 146 6.3 | 2.5 | 5.0 | 1.9 | Iris-virginica | . 147 6.5 | 3.0 | 5.2 | 2.0 | Iris-virginica | . 148 6.2 | 3.4 | 5.4 | 2.3 | Iris-virginica | . 149 5.9 | 3.0 | 5.1 | 1.8 | Iris-virginica | . 150 rows × 5 columns . X = dataset.iloc[:, :-1].values y = dataset.iloc[:, 4].values # Train Test Split from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # Feature Scaling from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X_train) X_train = scaler.transform(X_train) X_test = scaler.transform(X_test) . KNN . from sklearn.neighbors import KNeighborsClassifier classifier = KNeighborsClassifier(n_neighbors=5) classifier.fit(X_train, y_train) . KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights=&#39;uniform&#39;) . y_pred = classifier.predict(X_test) # Evaluating from sklearn.metrics import classification_report, confusion_matrix print(classification_report(y_test, y_pred)) . precision recall f1-score support Iris-setosa 1.00 1.00 1.00 8 Iris-versicolor 0.93 0.88 0.90 16 Iris-virginica 0.71 0.83 0.77 6 accuracy 0.90 30 macro avg 0.88 0.90 0.89 30 weighted avg 0.91 0.90 0.90 30 . K-means algorithm . K-means: What&#39;s it for . Unsupervised Learning for clustering | Non-hierarchical cluster / hierarchical cluster | . . The K-means steps are: . Select the value of K, to decide the number of clusters to be formed. | Select random K points which will act as centroids | Assign each data point, based on their distance from the randomly selected points (Centroid), to the nearest/closest centroid which will form the predefined clusters. | place a new centroid of each cluster. | Repeat step no.3 | If any reassignment occurs, then go to step-4 else go to Step 7. | Finish | Set randomly centeroid in step2, so It is important first value . to use effectively setting automatically initial centroid | . Reference . KNN (K-Nearest Neighbors) #1 | K Means Clustering Simplified in Python | K-Nearest Neighbors Algorithm in Python and Scikit-Learn | .",
            "url": "https://interkid.github.io/My_Research/2021/10/05/KNN.html",
            "relUrl": "/2021/10/05/KNN.html",
            "date": " • Oct 5, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://interkid.github.io/My_Research/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://interkid.github.io/My_Research/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . I am Kaito Honda software Deveoper in Japan.I am launching my career in data science. . I am lover of Science / Math. . . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://interkid.github.io/My_Research/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://interkid.github.io/My_Research/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}