{
  
    
        "post0": {
            "title": "Title",
            "content": "install surf2stl-python . !git clone https://github.com/asahidari/surf2stl-python . Cloning into &#39;surf2stl-python&#39;... remote: Enumerating objects: 19, done. remote: Counting objects: 100% (19/19), done. remote: Compressing objects: 100% (16/16), done. remote: Total 19 (delta 4), reused 17 (delta 2), pack-reused 0 Unpacking objects: 100% (19/19), done. . cd surf2stl-python . /content/surf2stl-python . How to draw CalbiYau Manifold . $$ z^n_1 + z^n_2 = 1 $$parameter$ z_1, z_2$ is defined below . $$ z_1= e^{iÏ†}[cos(x + iy)]^ frac2{n} $$$$ z_2= e^{iÏ†}[sin (x + iy)]^ frac2{n} $$$$ Ï†_1= frac{2Ï€k_1}{n} (0 â‰¦ k &lt; n) $$$$ Ï†_2= frac{2Ï€k_1}{n} (0 â‰¦ k &lt; n) $$ . Parameter k1 and k2 individually take Integer values from 0 to n - 1, and results in n x n parts of the manifold(manupulate x, y each pattern in $nxn=n^2$) . | to visualize Calabi-Yau manifold means that to satisfy equation $z^n_1 + z^n_2 = 1$ ,then we can get z1, z2 by moving parameter x,y and integer k1, k2 . | $z_1, z_2$ spread 4Dimention thinking considering real number&amp;imaginary number($Re(z_1),Im(z_1),Re(z_2),Im(z_2)$ ), so we should think to reduce dimention | reduce $Im(z_1),Im(z_2)$ then make $(Re(z1),Re(z2),Im(z1)cos(a)+Im(z2)sin(a))$ 3D | . Import library . import numpy as np import math, cmath # cmath: è¤‡ç´ æ•°ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D import matplotlib.ticker as plticker from matplotlib import cm from scipy.spatial import Delaunay import surf2stl as s2s . Set Parameter . N = 9 # Dimension a = 0.4 row, col = 30, 30 writeSTL = False . define function for caculation . def calcZ1(x, y, k, n): return cmath.exp(1j*(2*cmath.pi*k/n)) * (cmath.cos(x+y*1j)**(2/n)) def calcZ2(x, y, k, n): return cmath.exp(1j*(2*cmath.pi*k/n)) * (cmath.sin(x+y*1j)**(2/n)) def calcZ1Real(x, y, k, n): return (calcZ1(x, y, k, n)).real def calcZ2Real(x, y, k, n): return (calcZ2(x, y, k, n)).real def calcZ(x, y, k1_, k2_, n, a_): z1 = calcZ1(x, y, k1, n) z2 = calcZ2(x, y, k2, n) return z1.imag * math.cos(a_) + z2.imag*math.sin(a_) . Draw . x = np.linspace(0, math.pi/2, col) y = np.linspace(-math.pi/2, math.pi/2, row) x, y = np.meshgrid(x, y) # init graph fig = plt.figure(figsize=(18,8)) for n in range(2, N): ax = fig.add_subplot(2, 4, n - 1, projection=&#39;3d&#39;) ax.view_init(elev=15, azim=15) ax.set_title(&quot;n=%d&quot; % n) ax.set_xlabel(&#39;X&#39;) ax.set_ylabel(&#39;Y&#39;) loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals ax.xaxis.set_major_locator(loc) ax.yaxis.set_major_locator(loc) ax.zaxis.set_major_locator(loc) count = 0 for k1 in range(n): for k2 in range(n): # calc X, Y, Z values X = np.frompyfunc(calcZ1Real, 4, 1)(x, y, k1, n).astype(&#39;float32&#39;) Y = np.frompyfunc(calcZ2Real, 4, 1)(x, y, k2, n).astype(&#39;float32&#39;) Z = np.frompyfunc(calcZ, 6, 1)(x, y, k1, k2, n, a).astype(&#39;float32&#39;) ax.plot_surface(X, Y, Z, cmap=cm.ocean, linewidth=0) . Reference . Creating Calabi Yau Manifold in python | Calabi-Yauå¤šæ§˜ä½“ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã«å¯è¦–åŒ–ã™ã‚‹ | .",
            "url": "https://interkid.github.io/My_Research/2021/10/26/CreatingCalabiYauManifold.html",
            "relUrl": "/2021/10/26/CreatingCalabiYauManifold.html",
            "date": " â€¢ Oct 26, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "NewworkXã«ã‚ˆã‚‹å¯è¦–åŒ–/åˆ†æ",
            "content": "&#30446;&#27425; . åŸºæœ¬ | å¯†åº¦ã¨ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•° | ã‚¹ãƒ¢ãƒ¼ãƒ«ãƒ¯ãƒ¼ãƒ«ãƒ‰ç”Ÿæˆ | æ¬¡æ•°ã¨æ¬¡æ•°åˆ†å¸ƒ | ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ãƒªãƒ¼ä½œæˆ | è·é›¢ã¨ç›´å¾„ | ä¸­å¿ƒæ€§ | . NetworkXã§ã§ãã‚‹ã“ã¨ . ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ä½œæˆã®ã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ç°¡å˜ãªç”Ÿæˆ ã‚°ãƒ©ãƒ•ã®ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã¯ã‚·ãƒ³ãƒ—ãƒ«(ç¶ºéº—ãªãƒ¬ãƒ™ãƒ«ã§ã¯ãªã„) | . | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã®æ–‡è„ˆã§ã®ç”¨é€”ãŒå¤šã„ ex. ä¸­å¿ƒäººç‰©(ãƒãƒ–)ã‚’è¦‹ã¤ã‘ã¦æ„ŸæŸ“åˆ¶å¾¡, ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æŠ½å‡ºã—ã¦ã€æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  ãªã© | . | . ã“ã®è¨˜äº‹ã®å‚è€ƒã¯ã»ã¼ã“ã¡ã‚‰å¼•ç”¨ğŸ™ https://www.youtube.com/watch?v=AC4u1PYlveU | å…¬å¼ref https://networkx.org/documentation/stable/reference/index.html | . &#22522;&#26412; . import networkx as nx # NetworkXã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ import matplotlib.pyplot as plt import numpy as np . G = nx.Graph([(1, 2), (2, 3), (3, 1)]) # G = nx.Graph() # ç©ºã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹å ´åˆ nx.draw(G, with_labels=True,font_family=&#39;sans-serif&#39;) # ãƒ©ãƒ™ãƒ«ã‚’Trueã«ã—ã¦ç•ªå·ã®å¯è¦–åŒ– . æ•°å­—ä»¥å¤–ã®æ—¥æœ¬èª,æ–‡å­—ã®è¨˜è¿°ã‚‚è¨­å®šã‚’åŠ ãˆã‚Œã°å¯èƒ½(defaultã§æ–‡å­—åŒ–ã‘ã™ã‚‹) | . G.add_node(4) # 4ã¯ç¹‹ãŒã£ã¦ãªã„ã®ã§é ãã«é…ç½® nx.draw(G, with_labels=True) . G.add_edge(1,4) nx.draw(G, with_labels=True) . n = [5, 6, 7] G.add_nodes_from(n) # è¤‡æ•°ãƒªãƒ³ã‚¯ã®è¿½åŠ  e = [(5,6), (3,7), (4,6)] G.add_edges_from(e) nx.draw(G, with_labels=True) . G.remove_node(4) nx.draw(G, with_labels=True) . G.remove_edges_from([(1,2), (2,3)]) nx.draw(G, with_labels=True) . rnd = nx.gnp_random_graph(10, 0.5) # (ç¬¬1å¼•æ•°ã€€ãƒãƒ¼ãƒ‰ã®æ•°, ç¬¬ï¼’å¼•æ•°ã€€ã‚¨ãƒƒã‚¸ã‚’å¼•ãç¢ºç‡(1ã§å…¨ã¦å¼•ã)) pos=nx.circular_layout(rnd) # å††å‘¨ä¸Šã«ç­‰é–“éš”ã§é…ç½® #pos = nx.spring_layout(rnd) # ãƒãƒãƒ¢ãƒ‡ãƒ«(ç¹‹ãŒã‚Š(ãƒãƒ)ãŒè‡ªç„¶ã®é•·ã•) #pos = nx.random_layout(rnd) #ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ plt.title(&#39;random graph&#39;) nx.draw(rnd, pos, with_labels=True) . K_10 = nx.complete_graph(10) pos=nx.spring_layout(K_10) plt.title(&#39;complete graph&#39;) nx.draw(K_10, pos, with_labels=True) . star = nx.star_graph(100) pos=nx.spring_layout(star) plt.title(&#39;star graph&#39;) nx.draw(star, pos, with_labels=True) . wheel = nx.wheel_graph(10) pos=nx.spring_layout(wheel) plt.title(&#39;wheel graph&#39;) nx.draw(wheel, pos, with_labels=True) . &#23494;&#24230;&#12392;&#12463;&#12521;&#12473;&#12479;&#20418;&#25968; . å¯†åº¦: ã©ã‚Œã ã‘ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒå¯†é›†ã—ã¦ã„ã‚‹ã‹ . å¯†åº¦ã‚’æ±‚ã‚ã‚‹å¼ $$ density = ãƒªãƒ³ã‚¯ã®ç·æ•° / ãƒãƒ¼ãƒ‰ã®ãƒšã‚¢ã®ç·æ•° = frac{m}{n(n-1) -2} $$ . %matplotlib inline import networkx as nx # NetworkXã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ import matplotlib.pyplot as plt import numpy as np # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç”Ÿæˆ G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (3, 4), (4,5), (4,6),(5,6)]) nx.draw(G, with_labels=True) # ãƒ©ãƒ™ãƒ«ã‚’Trueã«ã—ã¦ç•ªå·ã®å¯è¦–åŒ– . ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•° : éš£æ¥ãƒãƒ¼ãƒ‰åŒå£«ãŒã©ã®ãã‚‰ã„ç¹‹ãŒã£ã¦ã„ã‚‹ã‹ (æ•°å€¤åŒ–ã®æ•°å¼ã¯çœç•¥) . print(nx.average_clustering(G)) . 0.5833333333333334 . %matplotlib inline import networkx as nx # NetworkXã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ import matplotlib.pyplot as plt import numpy as np # ãƒ©ãƒ³ãƒ€ãƒ ã‚°ãƒ©ãƒ•ç”Ÿæˆ rnd = nx.gnp_random_graph(10, 0.1) #pos=nx.spring_layout(rnd) pos=nx.circular_layout(rnd) #pos = nx.random_layout(rnd) plt.title(&#39;random graph&#39;) nx.draw(rnd, pos, with_labels=True) print(&#39;density:&#39;, nx.density(rnd), &#39;, clustering coefficient:&#39;, nx.average_clustering(rnd)) . density: 0.044444444444444446 , clustering coefficient: 0.0 . cycle = nx.cycle_graph(10) pos=nx.spring_layout(cycle) #pos=nx.circular_layout(cycle) #pos=nx.random_layout(cycle) plt.title(&#39;cycle graph&#39;) nx.draw(cycle, pos, with_labels=True) print(&#39;density:&#39;, nx.density(cycle), &#39;, clustering coefficient:&#39;, nx.average_clustering(cycle)) . density: 0.2222222222222222 , clustering coefficient: 0.0 . K_10 = nx.complete_graph(10) pos=nx.spring_layout(K_10) plt.title(&#39;complete graph&#39;) nx.draw(K_10, pos, with_labels=True) print(&#39;density:&#39;, nx.density(K_10), &#39;, clustering coefficient:&#39;, nx.average_clustering(K_10)) . density: 1.0 , clustering coefficient: 1.0 . &#12473;&#12514;&#12540;&#12523;&#12527;&#12540;&#12523;&#12489;&#12493;&#12483;&#12488;&#12527;&#12540;&#12463;&#29983;&#25104; . çµŒè·¯é•·ãŒé•·ã„&amp; é«˜åº¦ã«ã‚¯ãƒ©ã‚¹ã‚¿åŒ–ã‚’å…¼ã­å‚™ãˆãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ . n = 100 # ãƒãƒ¼ãƒ‰æ•° k = 4 # æ¬¡æ•° p = 0.1 # ãƒªãƒ³ã‚¯ã¤ãªãæ›¿ãˆç¢ºç‡ print(&#39;NetworkXã®watts_strogatz_graph()ã‚ˆã‚Šç”Ÿæˆ&#39;) G1 = nx.watts_strogatz_graph(n, k, p) pos = nx.circular_layout(G1) print(nx.info(G1)) # ç¨®ã€…ã®æƒ…å ±ã‚’å‡ºåŠ› print(&#39;ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•°ï¼š&#39;, nx.average_clustering(G1)) # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã®ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•°ã‚’å‡ºåŠ› nx.draw(G1, pos) plt.show() . NetworkXã®watts_strogatz_graph()ã‚ˆã‚Šç”Ÿæˆ Graph with 100 nodes and 200 edges ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•°ï¼š 0.42566666666666664 . def gen_WS_network(n, k, p, seed=None): if seed is not None: np.random.seed(seed=seed) G = nx.Graph() G.add_nodes_from(list(range(n))) for i in range(n): for j in range(k//2): G.add_edge(i, (i+j+1)%n) # k/2æœ¬ãƒªãƒ³ã‚¯ã‚’å¼µã‚‹ for (u,v) in G.edges(): if np.random.rand() &lt; p: # pã®ç¢ºç‡ã§ã¤ãªãæ›¿ãˆ G.remove_edge(u, v) new_node = (u+np.random.randint(n-1)+1)%n # æ–°ã—ã„æ¥ç¶šå…ˆã¨ã—ã¦u+1ã‹ã‚‰u-1ã¾ã§ã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã¶ while G.has_edge(u, new_node) == True: # æ—¢å­˜ãƒªãƒ³ã‚¯ã¯é™¤å¤– new_node = (u+np.random.randint(n-1)+1)%n G.add_edge(u, new_node) return G . n = 100 k = 4 p = 0.1 print(&#39;è‡ªä½œé–¢æ•°ã«ã‚ˆã‚‹ç”Ÿæˆ&#39;) G2 = gen_WS_network(n, k, p) pos = nx.circular_layout(G2) print(nx.info(G2)) print(&#39;ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•°ï¼š&#39;, nx.average_clustering(G2)) nx.draw(G2, pos) plt.show() . è‡ªä½œé–¢æ•°ã«ã‚ˆã‚‹ç”Ÿæˆ Graph with 100 nodes and 200 edges ã‚¯ãƒ©ã‚¹ã‚¿ä¿‚æ•°ï¼š 0.3556190476190476 . &#27425;&#25968;&#12392;&#27425;&#25968;&#20998;&#24067; . æ¬¡æ•°: ãƒãƒ¼ãƒ‰(é ‚ç‚¹)ãŒæŒã¤ãƒªãƒ³ã‚¯ï¼ˆè¾º)ã®æ•° å¹³å‡æ¬¡æ•°: æ¬¡æ•°kã®å¹³å‡å€¤ æ¬¡æ•°åˆ†å¸ƒ: æ¬¡æ•°ãŒå…¨ãƒãƒ¼ãƒ‰ã«å ã‚ã‚‹å‰²åˆ: p(k) æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ã™ã“ã¨ãŒå¤šã„ . G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (4,5)]) print(nx.info(G)) print(G.nodes()) nx.draw(G, with_labels=True) # ãƒ©ãƒ™ãƒ«ã‚’Trueã«ã—ã¦ç•ªå·ã®å¯è¦–åŒ– . Graph with 5 nodes and 5 edges [1, 2, 3, 4, 5] . print(nx.degree_histogram(G)) # æ™‚æ•°ã®å€‹æ•°ã‚’å‡ºåŠ› degree_dist = [i/5 for i in nx.degree_histogram(G)] plt.rcParams[&#39;font.size&#39;] = 20 plt.bar(range(5), height = degree_dist) # æ™‚æ•°ã®å‰²åˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’å‡ºåŠ› plt.xlabel(&#39;$k$&#39;) plt.ylabel(&#39;$p(k)$&#39;) plt.ylim(0,1) . [0, 2, 2, 0, 1] . (0.0, 1.0) . &#12473;&#12465;&#12540;&#12523;&#12501;&#12522;&#12540;&#12493;&#12483;&#12488;&#12527;&#12540;&#12463; . å¤šæ•°ãŒå°‘æ•°ã¨ã¤ãªãŒã‚Šã€å°‘æ•°ãŒå¤šæ•°ã¨ã¤ãªãŒã£ã¦ã„ã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(BAãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†) ex WWW, ä¿³å„ªã®å…±æ¼”é–¢ä¿‚ æ™‚æ•°åˆ†å¸ƒã¯ã¹ãå‰‡ã¨ãªã‚‹ å‚è€ƒ: https://syodokukai.exblog.jp/20771928/ . n = 100 m = 4 print(&#39;NetworkX.barabasi_albert_graph()&#39;) G1 = nx.barabasi_albert_graph(n, m) print(nx.info(G1)) nx.draw(G1) plt.show() . NetworkX.barabasi_albert_graph() Graph with 100 nodes and 384 edges . n = 5000 m = 4 # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç”Ÿæˆ G = nx.barabasi_albert_graph(n, m) # çµ„ã¿è¾¼ã¿é–¢æ•°ã§ç”Ÿæˆ # G = gen_BA_network(n, m) # è‡ªä½œé–¢æ•°ã§ç”Ÿæˆ k = [i for i,x in enumerate(nx.degree_histogram(G)) if x != 0] degree_dist = [i/n for i in nx.degree_histogram(G) if i != 0] print(k) print(degree_dist) plt.xscale(&#39;log&#39;) plt.yscale(&#39;log&#39;) plt.ylim(0.0001,1) plt.scatter(k, degree_dist) . [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 62, 63, 65, 67, 72, 73, 74, 75, 76, 77, 81, 85, 87, 93, 94, 96, 97, 102, 107, 114, 115, 120, 122, 128, 201, 248, 267] [0.3324, 0.1938, 0.1154, 0.0776, 0.0542, 0.0396, 0.0308, 0.0254, 0.0188, 0.0152, 0.0118, 0.0106, 0.008, 0.007, 0.0056, 0.0048, 0.0052, 0.0034, 0.0038, 0.0024, 0.0028, 0.0014, 0.0018, 0.0012, 0.0022, 0.0016, 0.0018, 0.0012, 0.001, 0.0012, 0.0008, 0.0012, 0.0012, 0.0008, 0.0002, 0.001, 0.0006, 0.0012, 0.0002, 0.0004, 0.0006, 0.0004, 0.0004, 0.0002, 0.0004, 0.0006, 0.0004, 0.0004, 0.0004, 0.0002, 0.0002, 0.0002, 0.0004, 0.0002, 0.0002, 0.0004, 0.0004, 0.0002, 0.0002, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002] . &lt;matplotlib.collections.PathCollection at 0x7f1c8bddf050&gt; . &#36317;&#38626; . è·é›¢: ãƒãƒ¼ãƒ‰ãƒšã‚¢é–“ã®æœ€çŸ­çµŒè·¯ã®é•·ã• | å¹³å‡è·é›¢: å…¨ãƒšã‚¢ã®è·é›¢ã®å¹³å‡å€¤ | ç›´å¾„: å…¨ãƒšã‚¢ã®è·é›¢ã®ä¸­ã§æœ€å¤§ã®ã‚‚ã® | . G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (3, 4), (4,5), (4,6),(5,6)]) nx.draw(G, with_labels=True) # ãƒ©ãƒ™ãƒ«ã‚’Trueã«ã—ã¦ç•ªå·ã®å¯è¦–åŒ– . print(nx.shortest_path_length(G, 1, 2)) print(nx.shortest_path_length(G, 3, 6)) . 1 2 . print(nx.shortest_path(G, 1, 2)) print(nx.shortest_path(G, 2, 6)) print([p for p in nx.all_shortest_paths(G, 2, 6)]) . [1, 2] [2, 1, 4, 6] [[2, 1, 4, 6], [2, 1, 5, 6]] . print(&#39;L=&#39;, nx.average_shortest_path_length(G)) print(&#39;D=&#39;, nx.diameter(G)) . L= 1.5333333333333334 D= 3 . &#20013;&#24515;&#24615;(Centrality) . &quot;ä¸­å¿ƒ&quot;ã®æŒ‡æ¨™ . æ¬¡æ•°ä¸­å¿ƒæ€§: æ¬¡æ•°(ãƒãƒ¼ãƒ‰ãŒæŒã¤ãƒªãƒ³ã‚¯ã®æ•°)ã§æ±ºã‚ã‚‹ / æ­£è¦åŒ–ã—ãŸå€¤ã‚’ç®—å‡º | è¿‘æ¥ä¸­å¿ƒæ€§: ä»–ã®å…¨ã¦ä»–ã®å…¨ã¦ã®ãƒãƒ¼ãƒ‰ã¸ã®è·é›¢(æœ€çŸ­çµŒè·¯é•·)ã®å¹³å‡å€¤ã®é€†æ•° | ä»–ã«ã‚‚æŒ‡æ¨™ã‚ã‚Š | . æ´»ç”¨: snsã®ä¸­å¿ƒæ€§ãªã© . G = nx.Graph([(1, 2), (1,3), (1,4), (1,5), (3, 4), (4,5), (4,6),(5,6)]) nx.draw(G, with_labels=True) # ãƒ©ãƒ™ãƒ«ã‚’Trueã«ã—ã¦ç•ªå·ã®å¯è¦–åŒ– print(&#39;Degree Centrality&#39;, nx.degree_centrality(G)) # æ¬¡æ•°ä¸­å¿ƒæ€§ print(&#39;Closeness Centrality&#39;, nx.closeness_centrality(G)) # è¿‘æ¥ä¸­å¿ƒæ€§ . Degree Centrality {1: 0.8, 2: 0.2, 3: 0.4, 4: 0.8, 5: 0.6000000000000001, 6: 0.4} Closeness Centrality {1: 0.8333333333333334, 2: 0.5, 3: 0.625, 4: 0.8333333333333334, 5: 0.7142857142857143, 6: 0.5555555555555556} .",
            "url": "https://interkid.github.io/My_Research/2021/10/20/NetworkVisualization.html",
            "relUrl": "/2021/10/20/NetworkVisualization.html",
            "date": " â€¢ Oct 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "LSTM Algorithm & Implementation",
            "content": "Algorithm . Long-term-short-memory . . . TIme Series Analysis . purpose . Description | Modeling .. inference model and grasp feature time series | Prediction | Control .. manipulate variables to fluctuate purpose variable | TIme Series Analysis in RNN . RNN dose&#39;nt require prior knowledge for modeling trends &amp; period is learned from data autmatically | . | RNN weaksness when prediction of stock if there are only 3 years data, RNN can&#39;t perform well | . | . . Compare for methods in Time Series Forecasting . RNN(LSTM) is more expressionable in terms of function (but Blackbox) . Implementaion (pytorch) . Model Define . import torch import torch.nn as nn . input_dim = 5 # e.g. input of dimension 5 will look like this [1, 3, 8, 2, 3] hidden_dim = 10 # if the hidden dimension is 3 [3, 5, 4] n_layers = 1 # the number of LSTM layers stacked lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True) . Input Data . batch_size = 1 seq_len = 1 # initialize input, hidden state, cell state(long_memory) inp = torch.randn(batch_size, seq_len, input_dim) hidden_state = torch.randn(n_layers, batch_size, hidden_dim) cell_state = torch.randn(n_layers, batch_size, hidden_dim) hidden = (hidden_state, cell_state) print(&quot;inp_size: {}, n hidden_state_size: {}, n cell_state_size: {}&quot;.format(inp.shape, hidden_state.shape, cell_state.shape)) hidden . inp_size: torch.Size([1, 1, 5]), hidden_state_size: torch.Size([1, 1, 10]), cell_state_size: torch.Size([1, 1, 10]) . (tensor([[[ 2.7525, -0.3706, -0.1003, -0.8155, 0.1962, 1.3871, 0.4509, 0.3741, 0.4785, -0.6127]]]), tensor([[[ 1.1783, -0.6752, -1.6241, 0.0391, -1.1110, -0.5538, -1.5670, 0.1072, 0.0810, -0.4173]]])) . out, hidden = lstm_layer(inp, hidden) print(&quot;Outout shape:&quot;, out.shape) print(&quot;Hiden&quot;, hidden) . Outout shape: torch.Size([1, 1, 10]) Hiden (tensor([[[ 0.1804, -0.1010, -0.3767, -0.0170, -0.0909, 0.0929, -0.4508, 0.0109, 0.1320, -0.1107]]], grad_fn=&lt;StackBackward&gt;), tensor([[[ 0.2725, -0.1367, -0.8260, -0.0767, -0.1377, 0.2064, -1.0127, 0.0231, 0.2400, -0.1765]]], grad_fn=&lt;StackBackward&gt;)) . .. LSTM cell process the input and hidden states at each time step . seq_len = 3 inp = torch.randn(batch_size, seq_len, input_dim) out, hidden = lstm_layer(inp, hidden) print(out.shape) . torch.Size([1, 3, 10]) . .. the output&#39;s 2nd dimension is 3, indicating that there were 3 outputs given by the LSTM. This corresponds to the length of our input sequence. . Reference . viya-recurrent-neural-network.pdf | Long Short-Term Memory: From Zero to Hero with PyTorch | .",
            "url": "https://interkid.github.io/My_Research/2021/10/09/LSTM_introduction.html",
            "relUrl": "/2021/10/09/LSTM_introduction.html",
            "date": " â€¢ Oct 9, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "KNN Algorithm",
            "content": "KNN: What&#39;s it for . simple classification or regeression algorithm simple = low accuracy rather than other Algorithm | . | Regression Find the K closest points to a sample point and return the average value | . | . . The KNN&#8217;s steps are: . Receive an unclassified data; | Measure the distance (Euclidian, Manhattan, Minkowski or Weighted) from the new data to all others data that is already classified; | Gets the K(K is a parameter that you difine) smaller distances; | Check the list of classes had the shortest distance and count the amount of each class that appears; | Takes as correct class the class that appeared the most times; | Classifies the new data with the class that you took in step 5; | How is it used? . Dimensionality reduction stage Avoid sparse data | . | . Implementation Iris dataset . import numpy as np import matplotlib.pyplot as plt import pandas as pd . Data . url = &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&quot; names = [&#39;sepal-length&#39;, &#39;sepal-width&#39;, &#39;petal-length&#39;, &#39;petal-width&#39;, &#39;Class&#39;] dataset = pd.read_csv(url, names=names) . dataset . sepal-length sepal-width petal-length petal-width Class . 0 5.1 | 3.5 | 1.4 | 0.2 | Iris-setosa | . 1 4.9 | 3.0 | 1.4 | 0.2 | Iris-setosa | . 2 4.7 | 3.2 | 1.3 | 0.2 | Iris-setosa | . 3 4.6 | 3.1 | 1.5 | 0.2 | Iris-setosa | . 4 5.0 | 3.6 | 1.4 | 0.2 | Iris-setosa | . ... ... | ... | ... | ... | ... | . 145 6.7 | 3.0 | 5.2 | 2.3 | Iris-virginica | . 146 6.3 | 2.5 | 5.0 | 1.9 | Iris-virginica | . 147 6.5 | 3.0 | 5.2 | 2.0 | Iris-virginica | . 148 6.2 | 3.4 | 5.4 | 2.3 | Iris-virginica | . 149 5.9 | 3.0 | 5.1 | 1.8 | Iris-virginica | . 150 rows Ã— 5 columns . X = dataset.iloc[:, :-1].values y = dataset.iloc[:, 4].values # Train Test Split from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # Feature Scaling from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X_train) X_train = scaler.transform(X_train) X_test = scaler.transform(X_test) . KNN . from sklearn.neighbors import KNeighborsClassifier classifier = KNeighborsClassifier(n_neighbors=5) classifier.fit(X_train, y_train) . KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights=&#39;uniform&#39;) . y_pred = classifier.predict(X_test) # Evaluating from sklearn.metrics import classification_report, confusion_matrix print(classification_report(y_test, y_pred)) . precision recall f1-score support Iris-setosa 1.00 1.00 1.00 8 Iris-versicolor 0.93 0.88 0.90 16 Iris-virginica 0.71 0.83 0.77 6 accuracy 0.90 30 macro avg 0.88 0.90 0.89 30 weighted avg 0.91 0.90 0.90 30 . K-means algorithm . K-means: What&#39;s it for . Unsupervised Learning for clustering | Non-hierarchical cluster / hierarchical cluster | . . The K-means steps are: . Select the value of K, to decide the number of clusters to be formed. | Select random K points which will act as centroids | Assign each data point, based on their distance from the randomly selected points (Centroid), to the nearest/closest centroid which will form the predefined clusters. | place a new centroid of each cluster. | Repeat step no.3 | If any reassignment occurs, then go to step-4 else go to Step 7. | Finish | Set randomly centeroid in step2, so It is important first value . to use effectively setting automatically initial centroid | . Reference . KNN (K-Nearest Neighbors) #1 | K Means Clustering Simplified in Python | K-Nearest Neighbors Algorithm in Python and Scikit-Learn | .",
            "url": "https://interkid.github.io/My_Research/2021/10/05/KNN.html",
            "relUrl": "/2021/10/05/KNN.html",
            "date": " â€¢ Oct 5, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.â†© . 2. This is the other footnote. You can even have a link!â†© .",
            "url": "https://interkid.github.io/My_Research/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " â€¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a â€œlevel 1 headingâ€ in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Hereâ€™s a footnote 1. Hereâ€™s a horizontal rule: . . Lists . Hereâ€™s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes â€¦andâ€¦ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.Â &#8617; . |",
            "url": "https://interkid.github.io/My_Research/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " â€¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . I am Kaito Honda software Deveoper in Japan.I am launching my career in data science. . I am lover of Science / Math. . . a blogging platform that natively supports Jupyter notebooks in addition to other formats.Â &#8617; . |",
          "url": "https://interkid.github.io/My_Research/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ â€œsitemap.xmlâ€ | absolute_url }} | .",
          "url": "https://interkid.github.io/My_Research/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}