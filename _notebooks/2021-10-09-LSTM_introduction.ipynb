{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyLEzYxTWYqWv2xrZhE4pH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad6qxifDJTqy"
      },
      "source": [
        "# LSTM Algorithm & Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-2O3zZJakw"
      },
      "source": [
        "## Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaEjDSNOMANq"
      },
      "source": [
        "### Long-term-short-memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NuQ6x1mJp60"
      },
      "source": [
        "![](https://github.com/interkid/My_Research/blob/master/images/lSTM_forumulatoin.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3PgXy7opzb8"
      },
      "source": [
        "![](https://github.com/interkid/My_Research/blob/master/images/lstm.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3YEuQ30tR8j"
      },
      "source": [
        "## TIme Series Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SyTRxCUtWQR"
      },
      "source": [
        "purpose \n",
        "\n",
        "1. Description\n",
        "2. Modeling .. inference model and grasp feature time series\n",
        "3. Prediction\n",
        "4. Control .. manipulate variables to fluctuate purpose variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgkN7AZC5pQS"
      },
      "source": [
        "### TIme Series Analysis in RNN\n",
        "- RNN dose'nt require  prior knowledge for modeling\n",
        "  - trends & period is learned from data autmatically\n",
        "- RNN weaksness\n",
        "  - when prediction of stock if there are only 3 years data, RNN can't perform well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yYpFokS8PLA"
      },
      "source": [
        "![](https://github.com/interkid/My_Research/blob/master/images/rnn_choice.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUcN8495oT2d"
      },
      "source": [
        "## Compare  for methods in  Time Series Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJW9KWTQr0db"
      },
      "source": [
        " RNN(LSTM) is more expressionable in terms of function (but Blackbox)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzzFdi2TJco0"
      },
      "source": [
        "## Implementaion (pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du6nm5-P-vOv"
      },
      "source": [
        "#### Model Define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izs4EWSkJRS5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQqp2ug19rzT"
      },
      "source": [
        "input_dim = 5 # e.g. input of dimension 5 will look like this [1, 3, 8, 2, 3]\n",
        "hidden_dim = 10 #   if the hidden dimension is 3 [3, 5, 4]\n",
        "n_layers = 1 # the number of LSTM layers stacked\n",
        "\n",
        "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4TodWWn-zHB"
      },
      "source": [
        "#### Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe_1yXnb-ILK",
        "outputId": "5265abbb-bd79-4d80-de9b-e158d8895f2f"
      },
      "source": [
        "batch_size = 1\n",
        "seq_len = 1\n",
        "\n",
        "# initialize input, hidden state, cell state(long_memory)\n",
        "inp = torch.randn(batch_size, seq_len, input_dim)\n",
        "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
        "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
        "hidden = (hidden_state, cell_state)\n",
        "\n",
        "print(\"inp_size: {},\\n hidden_state_size: {},\\n cell_state_size: {}\".format(inp.shape, hidden_state.shape, cell_state.shape))\n",
        "hidden"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp_size: torch.Size([1, 1, 5]),\n",
            " hidden_state_size: torch.Size([1, 1, 10]),\n",
            " cell_state_size: torch.Size([1, 1, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 2.7525, -0.3706, -0.1003, -0.8155,  0.1962,  1.3871,  0.4509,\n",
              "            0.3741,  0.4785, -0.6127]]]),\n",
              " tensor([[[ 1.1783, -0.6752, -1.6241,  0.0391, -1.1110, -0.5538, -1.5670,\n",
              "            0.1072,  0.0810, -0.4173]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYB2bH9tBmbf",
        "outputId": "a418402b-0e6e-4d53-ebc4-409b8a13818e"
      },
      "source": [
        "# feed inp to lstm\n",
        "out, hidden = lstm_layer(inp, hidden)\n",
        "print(\"Outout shape:\", out.shape)\n",
        "print(\"Hiden\", hidden) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outout shape: torch.Size([1, 1, 10])\n",
            "Hiden (tensor([[[ 0.1804, -0.1010, -0.3767, -0.0170, -0.0909,  0.0929, -0.4508,\n",
            "           0.0109,  0.1320, -0.1107]]], grad_fn=<StackBackward>), tensor([[[ 0.2725, -0.1367, -0.8260, -0.0767, -0.1377,  0.2064, -1.0127,\n",
            "           0.0231,  0.2400, -0.1765]]], grad_fn=<StackBackward>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E-2U4i0B_7V"
      },
      "source": [
        ".. LSTM cell process the input and hidden states at each time step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWa6i9--_qtR",
        "outputId": "c0649c88-23d5-4860-d6b2-21cfb285ff71"
      },
      "source": [
        "seq_len = 3\n",
        "inp = torch.randn(batch_size, seq_len, input_dim)\n",
        "out, hidden = lstm_layer(inp, hidden)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fizd2InsCliD"
      },
      "source": [
        ".. the output's 2nd dimension is 3, indicating that there were 3 outputs given by the LSTM. This corresponds to the length of our input sequence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK-VcGxQ8ri-"
      },
      "source": [
        "### Reference\n",
        "* [viya-recurrent-neural-network.pdf](https://www.sas.com/content/dam/SAS/documents/marketing-whitepapers-ebooks/sas-whitepapers/ja/viya-recurrent-neural-network.pdf)\n",
        "* [Long Short-Term Memory: From Zero to Hero with PyTorch](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)\n"
      ]
    }
  ]
}