{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "a756c8aa-e3e8-49be-b4f2-d1d2dc3ac4a6",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "backup.ipynb のコピー",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00001-6bbddcb5-fa96-4341-b7b9-56cb79ec0bb5",
        "deepnote_cell_type": "markdown",
        "tags": [],
        "id": "n4RU9XM8kE3d"
      },
      "source": [
        "# \"Review of Deep Learning with PyTorch (Part 1 : Ch 01 - 08)\"\n",
        "> \"Review of content covered from Chapters 1 to 8\"\n",
        "\n",
        "- toc: false\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [image recognition, CIFAR-10]\n",
        "- image: images/dlwpt-screenshots/dlwpt-08-logo.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE-uQjbnkE3j"
      },
      "source": [
        "- This learning assessment was created by Ong-Ekken, leveraging materials from _Deep Learning with PyTorch_ (2021) from Manning. \n",
        "- Each subsection should not take more than 20 minutes to cover (especially Q1)\n",
        "- By the end of this review, you should be able to train (while Googling and refering to the textbook) a Deep ResNet Neural Network to perform a classification task between 4 types of images in CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp2TN2RokE3k",
        "outputId": "fe436099-8452-415d-f99c-9cc7c90584df"
      },
      "source": [
        "#hide\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"\"\"\n",
        "<style>\n",
        "  table {margin-left: 0 !important;}\n",
        "</style>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  table {margin-left: 0 !important;}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCS-y4rUkE3l"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import ipywidgets as widgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00001-64041990-d376-4c7e-9b42-a4b4588e04a8",
        "deepnote_cell_type": "markdown",
        "tags": [],
        "id": "jLnXRSJRkE3m"
      },
      "source": [
        "## 1. Working with PyTorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00003-69d4cb26-83a3-422a-91b7-4ef964b53a8a",
        "deepnote_cell_type": "code",
        "tags": [],
        "id": "CmLzH1NnkE3m"
      },
      "source": [
        "# data for Q1.\n",
        "py_list = [1,2,3,4]\n",
        "np_array = np.array([4,7,10,13])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOnMiOKVkE3m"
      },
      "source": [
        "### Q1.1. What is a Tensor? Why can't we just use numpy arrays or Python lists?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDHz7qQ5kE3o"
      },
      "source": [
        "### Q1.2. Convert both `py_list` and `np_array` to tensors, and name them `predictions` and `labels` respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGmeU-dOkE3p",
        "outputId": "4e8d9aef-ec16-4dd7-e527-80396c870185"
      },
      "source": [
        "# first convert `py_list`\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcjdgJDUkE3q",
        "outputId": "b602313c-e413-41f8-e9e8-7932fe929e2a"
      },
      "source": [
        "# then convert `np_array`\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 4,  7, 10, 13])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbzluK6FkE3q"
      },
      "source": [
        "### Q1.3. Find the absolute errors (losses) of `predictions` against `labels`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFqjzQ9gkE3r",
        "outputId": "63398dca-fa60-429f-9531-e0a08009693a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-3, -5, -7, -9])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUUqAzsikE3r"
      },
      "source": [
        "### Q1.4. Sum up all values in the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuCQn5t9kE3r",
        "outputId": "e35a765e-71a2-4da5-bea8-89ade20e25af"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-24)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-E39pSkE3s"
      },
      "source": [
        "### Q1.5. In a single function, how can we create:\n",
        "- a 5x5 tensor of zeroes\n",
        "- a 4x4 tensor of ones\n",
        "- a 3x3 tensor of random values between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4tjkCVJkE3s",
        "outputId": "43113f9a-9383-4f90-d924-e12843d88219"
      },
      "source": [
        "# 5x5 tensor of zeroes\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.9447, 0.4112, 0.5508, 0.3091, 0.6765],\n",
              "        [0.9771, 0.4540, 0.4889, 0.3915, 0.8193],\n",
              "        [0.4343, 0.2813, 0.0829, 0.2936, 0.7214],\n",
              "        [0.1688, 0.2734, 0.9265, 0.7302, 0.8511],\n",
              "        [0.0652, 0.4613, 0.8419, 0.1605, 0.9629]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_AnAN9QkE3s",
        "outputId": "5889519a-3970-4047-bde6-b28d9c74d62b"
      },
      "source": [
        "# 4x4 tensor of ones\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SUwqvpUkE3t",
        "outputId": "b729e1e4-0848-4564-b7ca-7f1fb1800b05"
      },
      "source": [
        "# 3x3 tensor of random values between -1 and 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywEPlqSpkE3t"
      },
      "source": [
        "### Q1.6. Where can we find more information about tensor operations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qyM88ln4kE3t",
        "outputId": "5fbf7e55-55bd-469b-978d-f5d7d899d501"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class Tensor in module torch:\n",
            "\n",
            "class Tensor(torch._C._TensorBase)\n",
            " |  Method resolution order:\n",
            " |      Tensor\n",
            " |      torch._C._TensorBase\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __abs__ = abs(...)\n",
            " |  \n",
            " |  __array__(self, dtype=None)\n",
            " |  \n",
            " |  __array_wrap__(self, array)\n",
            " |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
            " |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
            " |  \n",
            " |  __contains__(self, element)\n",
            " |      Check if `element` is present in tensor\n",
            " |      \n",
            " |      Args:\n",
            " |          element (Tensor or scalar): element to be checked\n",
            " |              for presence in current tensor\"\n",
            " |  \n",
            " |  __deepcopy__(self, memo)\n",
            " |  \n",
            " |  __dir__(self)\n",
            " |      Default dir() implementation.\n",
            " |  \n",
            " |  __floordiv__(self, other)\n",
            " |  \n",
            " |  __format__(self, format_spec)\n",
            " |      Default object formatter.\n",
            " |  \n",
            " |  __hash__(self)\n",
            " |      Return hash(self).\n",
            " |  \n",
            " |  __ipow__(self, other)\n",
            " |  \n",
            " |  __iter__(self)\n",
            " |  \n",
            " |  __itruediv__ = __idiv__(...)\n",
            " |  \n",
            " |  __len__(self)\n",
            " |      Return len(self).\n",
            " |  \n",
            " |  __neg__ = neg(...)\n",
            " |  \n",
            " |  __pow__ = pow(...)\n",
            " |  \n",
            " |  __rdiv__(self, other)\n",
            " |  \n",
            " |  __reduce_ex__(self, proto)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __reversed__(self)\n",
            " |      Reverses the tensor along dimension 0.\n",
            " |  \n",
            " |  __rfloordiv__(self, other)\n",
            " |  \n",
            " |  __rpow__(self, other)\n",
            " |  \n",
            " |  __rsub__(self, other)\n",
            " |  \n",
            " |  __rtruediv__ = __rdiv__(self, other)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  align_to(self, *names)\n",
            " |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
            " |      specified in :attr:`names`, adding size-one dims for any new names.\n",
            " |      \n",
            " |      All of the dims of :attr:`self` must be named in order to use this method.\n",
            " |      The resulting tensor is a view on the original tensor.\n",
            " |      \n",
            " |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
            " |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
            " |      the output tensor has a size-one dimension for each of those new names.\n",
            " |      \n",
            " |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
            " |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
            " |      that are not mentioned in :attr:`names`, in the order that they appear\n",
            " |      in :attr:`self`.\n",
            " |      \n",
            " |      Python 2 does not support Ellipsis but one may use a string literal\n",
            " |      instead (``'...'``).\n",
            " |      \n",
            " |      Args:\n",
            " |          names (iterable of str): The desired dimension ordering of the\n",
            " |              output tensor. May contain up to one Ellipsis that is expanded\n",
            " |              to all unmentioned dim names of :attr:`self`.\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
            " |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
            " |      \n",
            " |          # Move the F and E dims to the front while keeping the rest in order\n",
            " |          >>> named_tensor.align_to('F', 'E', ...)\n",
            " |      \n",
            " |      .. warning::\n",
            " |          The named tensor API is experimental and subject to change.\n",
            " |  \n",
            " |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
            " |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
            " |      \n",
            " |      The graph is differentiated using the chain rule. If the tensor is\n",
            " |      non-scalar (i.e. its data has more than one element) and requires\n",
            " |      gradient, the function additionally requires specifying ``gradient``.\n",
            " |      It should be a tensor of matching type and location, that contains\n",
            " |      the gradient of the differentiated function w.r.t. ``self``.\n",
            " |      \n",
            " |      This function accumulates gradients in the leaves - you might need to zero\n",
            " |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
            " |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
            " |      for details on the memory layout of accumulated gradients.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
            " |          in a user-specified CUDA stream context, see\n",
            " |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
            " |      \n",
            " |      Args:\n",
            " |          gradient (Tensor or None): Gradient w.r.t. the\n",
            " |              tensor. If it is a tensor, it will be automatically converted\n",
            " |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
            " |              None values can be specified for scalar Tensors or ones that\n",
            " |              don't require grad. If a None value would be acceptable then\n",
            " |              this argument is optional.\n",
            " |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
            " |              the grads will be freed. Note that in nearly all cases setting\n",
            " |              this option to True is not needed and often can be worked around\n",
            " |              in a much more efficient way. Defaults to the value of\n",
            " |              ``create_graph``.\n",
            " |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
            " |              be constructed, allowing to compute higher order derivative\n",
            " |              products. Defaults to ``False``.\n",
            " |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
            " |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
            " |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
            " |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
            " |              Tensors.\n",
            " |  \n",
            " |  detach(...)\n",
            " |      Returns a new Tensor, detached from the current graph.\n",
            " |      \n",
            " |      The result will never require gradient.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |        Returned Tensor shares the same storage with the original one.\n",
            " |        In-place modifications on either of them will be seen, and may trigger\n",
            " |        errors in correctness checks.\n",
            " |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
            " |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
            " |        also update the original tensor. Now, these in-place changes will not update the\n",
            " |        original tensor anymore, and will instead trigger an error.\n",
            " |        For sparse tensors:\n",
            " |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
            " |        returned tensor will not update the original tensor anymore, and will instead\n",
            " |        trigger an error.\n",
            " |  \n",
            " |  detach_(...)\n",
            " |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
            " |      Views cannot be detached in-place.\n",
            " |  \n",
            " |  is_shared(self)\n",
            " |      Checks if tensor is in shared memory.\n",
            " |      \n",
            " |      This is always ``True`` for CUDA tensors.\n",
            " |  \n",
            " |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
            " |      See :func:`torch.istft`\n",
            " |  \n",
            " |  lu(self, pivot=True, get_infos=False)\n",
            " |      See :func:`torch.lu`\n",
            " |  \n",
            " |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
            " |      See :func:`torch.norm`\n",
            " |  \n",
            " |  refine_names(self, *names)\n",
            " |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
            " |      \n",
            " |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
            " |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
            " |      refined to have the same name.\n",
            " |      \n",
            " |      Because named tensors can coexist with unnamed tensors, refining names\n",
            " |      gives a nice way to write named-tensor-aware code that works with both\n",
            " |      named and unnamed tensors.\n",
            " |      \n",
            " |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
            " |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
            " |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
            " |      corresponding indices of ``self.names``.\n",
            " |      \n",
            " |      Python 2 does not support Ellipsis but one may use a string literal\n",
            " |      instead (``'...'``).\n",
            " |      \n",
            " |      Args:\n",
            " |          names (iterable of str): The desired names of the output tensor. May\n",
            " |              contain up to one Ellipsis.\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
            " |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
            " |          >>> named_imgs.names\n",
            " |          ('N', 'C', 'H', 'W')\n",
            " |      \n",
            " |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
            " |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
            " |          >>> tensor.names\n",
            " |          ('A', None, None, 'B', 'C')\n",
            " |      \n",
            " |      .. warning::\n",
            " |          The named tensor API is experimental and subject to change.\n",
            " |  \n",
            " |  register_hook(self, hook)\n",
            " |      Registers a backward hook.\n",
            " |      \n",
            " |      The hook will be called every time a gradient with respect to the\n",
            " |      Tensor is computed. The hook should have the following signature::\n",
            " |      \n",
            " |          hook(grad) -> Tensor or None\n",
            " |      \n",
            " |      \n",
            " |      The hook should not modify its argument, but it can optionally return\n",
            " |      a new gradient which will be used in place of :attr:`grad`.\n",
            " |      \n",
            " |      This function returns a handle with a method ``handle.remove()``\n",
            " |      that removes the hook from the module.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
            " |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
            " |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
            " |          >>> v.grad\n",
            " |      \n",
            " |           2\n",
            " |           4\n",
            " |           6\n",
            " |          [torch.FloatTensor of size (3,)]\n",
            " |      \n",
            " |          >>> h.remove()  # removes the hook\n",
            " |  \n",
            " |  reinforce(self, reward)\n",
            " |  \n",
            " |  rename(self, *names, **rename_map)\n",
            " |      Renames dimension names of :attr:`self`.\n",
            " |      \n",
            " |      There are two main usages:\n",
            " |      \n",
            " |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
            " |      renamed as specified in the mapping :attr:`rename_map`.\n",
            " |      \n",
            " |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
            " |      dimensions positionally using :attr:`names`.\n",
            " |      Use ``self.rename(None)`` to drop names on a tensor.\n",
            " |      \n",
            " |      One cannot specify both positional args :attr:`names` and keyword args\n",
            " |      :attr:`rename_map`.\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
            " |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
            " |          >>> renamed_imgs.names\n",
            " |          ('batch', 'channels', 'H', 'W')\n",
            " |      \n",
            " |          >>> renamed_imgs = imgs.rename(None)\n",
            " |          >>> renamed_imgs.names\n",
            " |          (None,)\n",
            " |      \n",
            " |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
            " |          >>> renamed_imgs.names\n",
            " |          ('batch', 'channel', 'height', 'width')\n",
            " |      \n",
            " |      .. warning::\n",
            " |          The named tensor API is experimental and subject to change.\n",
            " |  \n",
            " |  rename_(self, *names, **rename_map)\n",
            " |      In-place version of :meth:`~Tensor.rename`.\n",
            " |  \n",
            " |  resize(self, *sizes)\n",
            " |  \n",
            " |  resize_as(self, tensor)\n",
            " |  \n",
            " |  retain_grad(self)\n",
            " |      Enables .grad attribute for non-leaf Tensors.\n",
            " |  \n",
            " |  share_memory_(self)\n",
            " |      Moves the underlying storage to shared memory.\n",
            " |      \n",
            " |      This is a no-op if the underlying storage is already in shared memory\n",
            " |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
            " |  \n",
            " |  split(self, split_size, dim=0)\n",
            " |      See :func:`torch.split`\n",
            " |  \n",
            " |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
            " |      See :func:`torch.stft`\n",
            " |      \n",
            " |      .. warning::\n",
            " |        This function changed signature at version 0.4.1. Calling with\n",
            " |        the previous signature may cause error or return incorrect result.\n",
            " |  \n",
            " |  unflatten(self, dim, sizes)\n",
            " |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
            " |      of sizes given by :attr:`sizes`.\n",
            " |      \n",
            " |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
            " |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
            " |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
            " |        of elements in the original dim being unflattened.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (Union[int, str]): Dimension to unflatten\n",
            " |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
            " |      \n",
            " |      Examples:\n",
            " |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
            " |          torch.Size([3, 2, 2, 1])\n",
            " |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
            " |          tensor([[[-1.1772,  0.0180],\n",
            " |                  [ 0.2412,  0.1431]],\n",
            " |      \n",
            " |                  [[-1.1819, -0.8899],\n",
            " |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
            " |      \n",
            " |      .. warning::\n",
            " |          The named tensor API is experimental and subject to change.\n",
            " |  \n",
            " |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
            " |      Returns the unique elements of the input tensor.\n",
            " |      \n",
            " |      See :func:`torch.unique`\n",
            " |  \n",
            " |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
            " |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
            " |      \n",
            " |      See :func:`torch.unique_consecutive`\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  __torch_function__(func, types, args=(), kwargs=None) from builtins.type\n",
            " |      This __torch_function__ implementation wraps subclasses such that\n",
            " |      methods called on subclasses return a subclass instance instead of\n",
            " |      a ``torch.Tensor`` instance.\n",
            " |      \n",
            " |      One corollary to this is that you need coverage for torch.Tensor\n",
            " |      methods if implementing __torch_function__ for subclasses.\n",
            " |      \n",
            " |      We recommend always calling ``super().__torch_function__`` as the base\n",
            " |      case when doing the above.\n",
            " |      \n",
            " |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  __cuda_array_interface__\n",
            " |      Array view description for cuda tensors.\n",
            " |      \n",
            " |      See:\n",
            " |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  grad\n",
            " |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
            " |      :func:`backward` computes gradients for ``self``.\n",
            " |      The attribute will then contain the gradients computed and future calls to\n",
            " |      :func:`backward` will accumulate (add) gradients into it.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __array_priority__ = 1000\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from torch._C._TensorBase:\n",
            " |  \n",
            " |  __add__(...)\n",
            " |  \n",
            " |  __and__(...)\n",
            " |  \n",
            " |  __bool__(...)\n",
            " |  \n",
            " |  __complex__(...)\n",
            " |  \n",
            " |  __delitem__(self, key, /)\n",
            " |      Delete self[key].\n",
            " |  \n",
            " |  __div__(...)\n",
            " |  \n",
            " |  __eq__(...)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __float__(...)\n",
            " |  \n",
            " |  __ge__(...)\n",
            " |      Return self>=value.\n",
            " |  \n",
            " |  __getitem__(self, key, /)\n",
            " |      Return self[key].\n",
            " |  \n",
            " |  __gt__(...)\n",
            " |      Return self>value.\n",
            " |  \n",
            " |  __iadd__(...)\n",
            " |  \n",
            " |  __iand__(...)\n",
            " |  \n",
            " |  __idiv__(...)\n",
            " |  \n",
            " |  __ifloordiv__(...)\n",
            " |  \n",
            " |  __ilshift__(...)\n",
            " |  \n",
            " |  __imod__(...)\n",
            " |  \n",
            " |  __imul__(...)\n",
            " |  \n",
            " |  __index__(...)\n",
            " |  \n",
            " |  __int__(...)\n",
            " |  \n",
            " |  __invert__(...)\n",
            " |  \n",
            " |  __ior__(...)\n",
            " |  \n",
            " |  __irshift__(...)\n",
            " |  \n",
            " |  __isub__(...)\n",
            " |  \n",
            " |  __ixor__(...)\n",
            " |  \n",
            " |  __le__(...)\n",
            " |      Return self<=value.\n",
            " |  \n",
            " |  __long__(...)\n",
            " |  \n",
            " |  __lshift__(...)\n",
            " |  \n",
            " |  __lt__(...)\n",
            " |      Return self<value.\n",
            " |  \n",
            " |  __matmul__(...)\n",
            " |  \n",
            " |  __mod__(...)\n",
            " |  \n",
            " |  __mul__(...)\n",
            " |  \n",
            " |  __ne__(...)\n",
            " |      Return self!=value.\n",
            " |  \n",
            " |  __nonzero__(...)\n",
            " |  \n",
            " |  __or__(...)\n",
            " |  \n",
            " |  __radd__(...)\n",
            " |  \n",
            " |  __rmul__(...)\n",
            " |  \n",
            " |  __rshift__(...)\n",
            " |  \n",
            " |  __setitem__(self, key, value, /)\n",
            " |      Set self[key] to value.\n",
            " |  \n",
            " |  __sub__(...)\n",
            " |  \n",
            " |  __truediv__(...)\n",
            " |  \n",
            " |  __xor__(...)\n",
            " |  \n",
            " |  abs(...)\n",
            " |      abs() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.abs`\n",
            " |  \n",
            " |  abs_(...)\n",
            " |      abs_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.abs`\n",
            " |  \n",
            " |  absolute(...)\n",
            " |      absolute() -> Tensor\n",
            " |      \n",
            " |      Alias for :func:`abs`\n",
            " |  \n",
            " |  absolute_(...)\n",
            " |      absolute_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.absolute`\n",
            " |      Alias for :func:`abs_`\n",
            " |  \n",
            " |  acos(...)\n",
            " |      acos() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.acos`\n",
            " |  \n",
            " |  acos_(...)\n",
            " |      acos_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.acos`\n",
            " |  \n",
            " |  acosh(...)\n",
            " |      acosh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.acosh`\n",
            " |  \n",
            " |  acosh_(...)\n",
            " |      acosh_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.acosh`\n",
            " |  \n",
            " |  add(...)\n",
            " |      add(other, *, alpha=1) -> Tensor\n",
            " |      \n",
            " |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
            " |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
            " |      :attr:`alpha` before being used.\n",
            " |      \n",
            " |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
            " |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
            " |      tensor\n",
            " |      \n",
            " |      See :func:`torch.add`\n",
            " |  \n",
            " |  add_(...)\n",
            " |      add_(other, *, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.add`\n",
            " |  \n",
            " |  addbmm(...)\n",
            " |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.addbmm`\n",
            " |  \n",
            " |  addbmm_(...)\n",
            " |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.addbmm`\n",
            " |  \n",
            " |  addcdiv(...)\n",
            " |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.addcdiv`\n",
            " |  \n",
            " |  addcdiv_(...)\n",
            " |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.addcdiv`\n",
            " |  \n",
            " |  addcmul(...)\n",
            " |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.addcmul`\n",
            " |  \n",
            " |  addcmul_(...)\n",
            " |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.addcmul`\n",
            " |  \n",
            " |  addmm(...)\n",
            " |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.addmm`\n",
            " |  \n",
            " |  addmm_(...)\n",
            " |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.addmm`\n",
            " |  \n",
            " |  addmv(...)\n",
            " |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.addmv`\n",
            " |  \n",
            " |  addmv_(...)\n",
            " |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.addmv`\n",
            " |  \n",
            " |  addr(...)\n",
            " |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.addr`\n",
            " |  \n",
            " |  addr_(...)\n",
            " |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.addr`\n",
            " |  \n",
            " |  align_as(...)\n",
            " |      align_as(other) -> Tensor\n",
            " |      \n",
            " |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
            " |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
            " |      \n",
            " |      This operation is useful for explicit broadcasting by names (see examples).\n",
            " |      \n",
            " |      All of the dims of :attr:`self` must be named in order to use this method.\n",
            " |      The resulting tensor is a view on the original tensor.\n",
            " |      \n",
            " |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
            " |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
            " |      the output tensor has a size-one dimension for each of those new names.\n",
            " |      \n",
            " |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          # Example 1: Applying a mask\n",
            " |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
            " |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
            " |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
            " |      \n",
            " |      \n",
            " |          # Example 2: Applying a per-channel-scale\n",
            " |          >>> def scale_channels(input, scale):\n",
            " |          >>>    scale = scale.refine_names('C')\n",
            " |          >>>    return input * scale.align_as(input)\n",
            " |      \n",
            " |          >>> num_channels = 3\n",
            " |          >>> scale = torch.randn(num_channels, names=('C',))\n",
            " |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
            " |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
            " |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
            " |      \n",
            " |          # scale_channels is agnostic to the dimension order of the input\n",
            " |          >>> scale_channels(imgs, scale)\n",
            " |          >>> scale_channels(more_imgs, scale)\n",
            " |          >>> scale_channels(videos, scale)\n",
            " |      \n",
            " |      .. warning::\n",
            " |          The named tensor API is experimental and subject to change.\n",
            " |  \n",
            " |  all(...)\n",
            " |      all(dim=None, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.all`\n",
            " |  \n",
            " |  allclose(...)\n",
            " |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.allclose`\n",
            " |  \n",
            " |  amax(...)\n",
            " |      amax(dim=None, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.amax`\n",
            " |  \n",
            " |  amin(...)\n",
            " |      amin(dim=None, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.amin`\n",
            " |  \n",
            " |  angle(...)\n",
            " |      angle() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.angle`\n",
            " |  \n",
            " |  any(...)\n",
            " |      any(dim=None, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.any`\n",
            " |  \n",
            " |  apply_(...)\n",
            " |      apply_(callable) -> Tensor\n",
            " |      \n",
            " |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
            " |      each element with the value returned by :attr:`callable`.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          This function only works with CPU tensors and should not be used in code\n",
            " |          sections that require high performance.\n",
            " |  \n",
            " |  arccos(...)\n",
            " |      arccos() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.arccos`\n",
            " |  \n",
            " |  arccos_(...)\n",
            " |      arccos_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.arccos`\n",
            " |  \n",
            " |  arccosh(...)\n",
            " |      acosh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.arccosh`\n",
            " |  \n",
            " |  arccosh_(...)\n",
            " |      acosh_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.arccosh`\n",
            " |  \n",
            " |  arcsin(...)\n",
            " |      arcsin() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.arcsin`\n",
            " |  \n",
            " |  arcsin_(...)\n",
            " |      arcsin_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.arcsin`\n",
            " |  \n",
            " |  arcsinh(...)\n",
            " |      arcsinh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.arcsinh`\n",
            " |  \n",
            " |  arcsinh_(...)\n",
            " |      arcsinh_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.arcsinh`\n",
            " |  \n",
            " |  arctan(...)\n",
            " |      arctan() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.arctan`\n",
            " |  \n",
            " |  arctan_(...)\n",
            " |      arctan_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.arctan`\n",
            " |  \n",
            " |  arctanh(...)\n",
            " |      arctanh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.arctanh`\n",
            " |  \n",
            " |  arctanh_(...)\n",
            " |      arctanh_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.arctanh`\n",
            " |  \n",
            " |  argmax(...)\n",
            " |      argmax(dim=None, keepdim=False) -> LongTensor\n",
            " |      \n",
            " |      See :func:`torch.argmax`\n",
            " |  \n",
            " |  argmin(...)\n",
            " |      argmin(dim=None, keepdim=False) -> LongTensor\n",
            " |      \n",
            " |      See :func:`torch.argmin`\n",
            " |  \n",
            " |  argsort(...)\n",
            " |      argsort(dim=-1, descending=False) -> LongTensor\n",
            " |      \n",
            " |      See :func:`torch.argsort`\n",
            " |  \n",
            " |  as_strided(...)\n",
            " |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.as_strided`\n",
            " |  \n",
            " |  as_strided_(...)\n",
            " |  \n",
            " |  as_subclass(...)\n",
            " |      as_subclass(cls) -> Tensor\n",
            " |      \n",
            " |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
            " |      in the output mirror changes in ``self``, and the output stays attached\n",
            " |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
            " |  \n",
            " |  asin(...)\n",
            " |      asin() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.asin`\n",
            " |  \n",
            " |  asin_(...)\n",
            " |      asin_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.asin`\n",
            " |  \n",
            " |  asinh(...)\n",
            " |      asinh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.asinh`\n",
            " |  \n",
            " |  asinh_(...)\n",
            " |      asinh_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.asinh`\n",
            " |  \n",
            " |  atan(...)\n",
            " |      atan() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.atan`\n",
            " |  \n",
            " |  atan2(...)\n",
            " |      atan2(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.atan2`\n",
            " |  \n",
            " |  atan2_(...)\n",
            " |      atan2_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.atan2`\n",
            " |  \n",
            " |  atan_(...)\n",
            " |      atan_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.atan`\n",
            " |  \n",
            " |  atanh(...)\n",
            " |      atanh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.atanh`\n",
            " |  \n",
            " |  atanh_(...)\n",
            " |      atanh_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.atanh`\n",
            " |  \n",
            " |  baddbmm(...)\n",
            " |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.baddbmm`\n",
            " |  \n",
            " |  baddbmm_(...)\n",
            " |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.baddbmm`\n",
            " |  \n",
            " |  bernoulli(...)\n",
            " |      bernoulli(*, generator=None) -> Tensor\n",
            " |      \n",
            " |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
            " |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
            " |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
            " |      \n",
            " |      See :func:`torch.bernoulli`\n",
            " |  \n",
            " |  bernoulli_(...)\n",
            " |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
            " |      \n",
            " |          Fills each location of :attr:`self` with an independent sample from\n",
            " |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
            " |          ``dtype``.\n",
            " |      \n",
            " |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
            " |      \n",
            " |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
            " |          drawing the binary random number.\n",
            " |      \n",
            " |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
            " |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
            " |      \n",
            " |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
            " |          floating point ``dtype``.\n",
            " |      \n",
            " |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
            " |  \n",
            " |  bfloat16(...)\n",
            " |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
            " |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  bincount(...)\n",
            " |      bincount(weights=None, minlength=0) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.bincount`\n",
            " |  \n",
            " |  bitwise_and(...)\n",
            " |      bitwise_and() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.bitwise_and`\n",
            " |  \n",
            " |  bitwise_and_(...)\n",
            " |      bitwise_and_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.bitwise_and`\n",
            " |  \n",
            " |  bitwise_not(...)\n",
            " |      bitwise_not() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.bitwise_not`\n",
            " |  \n",
            " |  bitwise_not_(...)\n",
            " |      bitwise_not_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.bitwise_not`\n",
            " |  \n",
            " |  bitwise_or(...)\n",
            " |      bitwise_or() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.bitwise_or`\n",
            " |  \n",
            " |  bitwise_or_(...)\n",
            " |      bitwise_or_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.bitwise_or`\n",
            " |  \n",
            " |  bitwise_xor(...)\n",
            " |      bitwise_xor() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.bitwise_xor`\n",
            " |  \n",
            " |  bitwise_xor_(...)\n",
            " |      bitwise_xor_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
            " |  \n",
            " |  bmm(...)\n",
            " |      bmm(batch2) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.bmm`\n",
            " |  \n",
            " |  bool(...)\n",
            " |      bool(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  broadcast_to(...)\n",
            " |      broadcast_to(shape) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.broadcast_to`.\n",
            " |  \n",
            " |  byte(...)\n",
            " |      byte(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  cauchy_(...)\n",
            " |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
            " |      \n",
            " |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
            " |      \n",
            " |      .. math::\n",
            " |      \n",
            " |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
            " |  \n",
            " |  ceil(...)\n",
            " |      ceil() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.ceil`\n",
            " |  \n",
            " |  ceil_(...)\n",
            " |      ceil_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.ceil`\n",
            " |  \n",
            " |  char(...)\n",
            " |      char(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  cholesky(...)\n",
            " |      cholesky(upper=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cholesky`\n",
            " |  \n",
            " |  cholesky_inverse(...)\n",
            " |      cholesky_inverse(upper=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cholesky_inverse`\n",
            " |  \n",
            " |  cholesky_solve(...)\n",
            " |      cholesky_solve(input2, upper=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cholesky_solve`\n",
            " |  \n",
            " |  chunk(...)\n",
            " |      chunk(chunks, dim=0) -> List of Tensors\n",
            " |      \n",
            " |      See :func:`torch.chunk`\n",
            " |  \n",
            " |  clamp(...)\n",
            " |      clamp(min, max) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.clamp`\n",
            " |  \n",
            " |  clamp_(...)\n",
            " |      clamp_(min, max) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.clamp`\n",
            " |  \n",
            " |  clamp_max(...)\n",
            " |  \n",
            " |  clamp_max_(...)\n",
            " |  \n",
            " |  clamp_min(...)\n",
            " |  \n",
            " |  clamp_min_(...)\n",
            " |  \n",
            " |  clip(...)\n",
            " |      clip(min, max) -> Tensor\n",
            " |      \n",
            " |      Alias for :meth:`~Tensor.clamp`.\n",
            " |  \n",
            " |  clip_(...)\n",
            " |      clip_(min, max) -> Tensor\n",
            " |      \n",
            " |      Alias for :meth:`~Tensor.clamp_`.\n",
            " |  \n",
            " |  clone(...)\n",
            " |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.clone`\n",
            " |  \n",
            " |  coalesce(...)\n",
            " |      coalesce() -> Tensor\n",
            " |      \n",
            " |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
            " |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
            " |      \n",
            " |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
            " |  \n",
            " |  conj(...)\n",
            " |      conj() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.conj`\n",
            " |  \n",
            " |  contiguous(...)\n",
            " |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
            " |      \n",
            " |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
            " |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
            " |      :attr:`self` tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.contiguous_format``.\n",
            " |  \n",
            " |  copy_(...)\n",
            " |      copy_(src, non_blocking=False) -> Tensor\n",
            " |      \n",
            " |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
            " |      :attr:`self`.\n",
            " |      \n",
            " |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
            " |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
            " |      different device.\n",
            " |      \n",
            " |      Args:\n",
            " |          src (Tensor): the source tensor to copy from\n",
            " |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
            " |              the copy may occur asynchronously with respect to the host. For other\n",
            " |              cases, this argument has no effect.\n",
            " |  \n",
            " |  copysign(...)\n",
            " |      copysign(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.copysign`\n",
            " |  \n",
            " |  copysign_(...)\n",
            " |      copysign_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.copysign`\n",
            " |  \n",
            " |  cos(...)\n",
            " |      cos() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cos`\n",
            " |  \n",
            " |  cos_(...)\n",
            " |      cos_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.cos`\n",
            " |  \n",
            " |  cosh(...)\n",
            " |      cosh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cosh`\n",
            " |  \n",
            " |  cosh_(...)\n",
            " |      cosh_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.cosh`\n",
            " |  \n",
            " |  count_nonzero(...)\n",
            " |      count_nonzero(dim=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.count_nonzero`\n",
            " |  \n",
            " |  cpu(...)\n",
            " |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      Returns a copy of this object in CPU memory.\n",
            " |      \n",
            " |      If this object is already in CPU memory and on the correct device,\n",
            " |      then no copy is performed and the original object is returned.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  cross(...)\n",
            " |      cross(other, dim=-1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cross`\n",
            " |  \n",
            " |  cuda(...)\n",
            " |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      Returns a copy of this object in CUDA memory.\n",
            " |      \n",
            " |      If this object is already in CUDA memory and on the correct device,\n",
            " |      then no copy is performed and the original object is returned.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (:class:`torch.device`): The destination GPU device.\n",
            " |              Defaults to the current CUDA device.\n",
            " |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
            " |              the copy will be asynchronous with respect to the host.\n",
            " |              Otherwise, the argument has no effect. Default: ``False``.\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  cummax(...)\n",
            " |      cummax(dim) -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.cummax`\n",
            " |  \n",
            " |  cummin(...)\n",
            " |      cummin(dim) -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.cummin`\n",
            " |  \n",
            " |  cumprod(...)\n",
            " |      cumprod(dim, dtype=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cumprod`\n",
            " |  \n",
            " |  cumprod_(...)\n",
            " |      cumprod_(dim, dtype=None) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.cumprod`\n",
            " |  \n",
            " |  cumsum(...)\n",
            " |      cumsum(dim, dtype=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.cumsum`\n",
            " |  \n",
            " |  cumsum_(...)\n",
            " |      cumsum_(dim, dtype=None) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.cumsum`\n",
            " |  \n",
            " |  data_ptr(...)\n",
            " |      data_ptr() -> int\n",
            " |      \n",
            " |      Returns the address of the first element of :attr:`self` tensor.\n",
            " |  \n",
            " |  deg2rad(...)\n",
            " |      deg2rad() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.deg2rad`\n",
            " |  \n",
            " |  deg2rad_(...)\n",
            " |      deg2rad_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.deg2rad`\n",
            " |  \n",
            " |  dense_dim(...)\n",
            " |      dense_dim() -> int\n",
            " |      \n",
            " |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is not a sparse tensor.\n",
            " |      \n",
            " |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
            " |  \n",
            " |  dequantize(...)\n",
            " |      dequantize() -> Tensor\n",
            " |      \n",
            " |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
            " |  \n",
            " |  det(...)\n",
            " |      det() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.det`\n",
            " |  \n",
            " |  diag(...)\n",
            " |      diag(diagonal=0) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.diag`\n",
            " |  \n",
            " |  diag_embed(...)\n",
            " |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.diag_embed`\n",
            " |  \n",
            " |  diagflat(...)\n",
            " |      diagflat(offset=0) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.diagflat`\n",
            " |  \n",
            " |  diagonal(...)\n",
            " |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.diagonal`\n",
            " |  \n",
            " |  digamma(...)\n",
            " |      digamma() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.digamma`\n",
            " |  \n",
            " |  digamma_(...)\n",
            " |      digamma_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.digamma`\n",
            " |  \n",
            " |  dim(...)\n",
            " |      dim() -> int\n",
            " |      \n",
            " |      Returns the number of dimensions of :attr:`self` tensor.\n",
            " |  \n",
            " |  dist(...)\n",
            " |      dist(other, p=2) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.dist`\n",
            " |  \n",
            " |  div(...)\n",
            " |      div(value) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.div`\n",
            " |  \n",
            " |  div_(...)\n",
            " |      div_(value) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.div`\n",
            " |  \n",
            " |  divide(...)\n",
            " |      divide(value) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.divide`\n",
            " |  \n",
            " |  divide_(...)\n",
            " |      divide_(value) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.divide`\n",
            " |  \n",
            " |  dot(...)\n",
            " |      dot(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.dot`\n",
            " |  \n",
            " |  double(...)\n",
            " |      double(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  eig(...)\n",
            " |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.eig`\n",
            " |  \n",
            " |  element_size(...)\n",
            " |      element_size() -> int\n",
            " |      \n",
            " |      Returns the size in bytes of an individual element.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> torch.tensor([]).element_size()\n",
            " |          4\n",
            " |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
            " |          1\n",
            " |  \n",
            " |  eq(...)\n",
            " |      eq(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.eq`\n",
            " |  \n",
            " |  eq_(...)\n",
            " |      eq_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.eq`\n",
            " |  \n",
            " |  equal(...)\n",
            " |      equal(other) -> bool\n",
            " |      \n",
            " |      See :func:`torch.equal`\n",
            " |  \n",
            " |  erf(...)\n",
            " |      erf() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.erf`\n",
            " |  \n",
            " |  erf_(...)\n",
            " |      erf_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.erf`\n",
            " |  \n",
            " |  erfc(...)\n",
            " |      erfc() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.erfc`\n",
            " |  \n",
            " |  erfc_(...)\n",
            " |      erfc_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.erfc`\n",
            " |  \n",
            " |  erfinv(...)\n",
            " |      erfinv() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.erfinv`\n",
            " |  \n",
            " |  erfinv_(...)\n",
            " |      erfinv_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.erfinv`\n",
            " |  \n",
            " |  exp(...)\n",
            " |      exp() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.exp`\n",
            " |  \n",
            " |  exp2(...)\n",
            " |      exp2() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.exp2`\n",
            " |  \n",
            " |  exp2_(...)\n",
            " |      exp2_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.exp2`\n",
            " |  \n",
            " |  exp_(...)\n",
            " |      exp_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.exp`\n",
            " |  \n",
            " |  expand(...)\n",
            " |      expand(*sizes) -> Tensor\n",
            " |      \n",
            " |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
            " |      to a larger size.\n",
            " |      \n",
            " |      Passing -1 as the size for a dimension means not changing the size of\n",
            " |      that dimension.\n",
            " |      \n",
            " |      Tensor can be also expanded to a larger number of dimensions, and the\n",
            " |      new ones will be appended at the front. For the new dimensions, the\n",
            " |      size cannot be set to -1.\n",
            " |      \n",
            " |      Expanding a tensor does not allocate new memory, but only creates a\n",
            " |      new view on the existing tensor where a dimension of size one is\n",
            " |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
            " |      of size 1 can be expanded to an arbitrary value without allocating new\n",
            " |      memory.\n",
            " |      \n",
            " |      Args:\n",
            " |          *sizes (torch.Size or int...): the desired expanded size\n",
            " |      \n",
            " |      .. warning::\n",
            " |      \n",
            " |          More than one element of an expanded tensor may refer to a single\n",
            " |          memory location. As a result, in-place operations (especially ones that\n",
            " |          are vectorized) may result in incorrect behavior. If you need to write\n",
            " |          to the tensors, please clone them first.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.tensor([[1], [2], [3]])\n",
            " |          >>> x.size()\n",
            " |          torch.Size([3, 1])\n",
            " |          >>> x.expand(3, 4)\n",
            " |          tensor([[ 1,  1,  1,  1],\n",
            " |                  [ 2,  2,  2,  2],\n",
            " |                  [ 3,  3,  3,  3]])\n",
            " |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
            " |          tensor([[ 1,  1,  1,  1],\n",
            " |                  [ 2,  2,  2,  2],\n",
            " |                  [ 3,  3,  3,  3]])\n",
            " |  \n",
            " |  expand_as(...)\n",
            " |      expand_as(other) -> Tensor\n",
            " |      \n",
            " |      Expand this tensor to the same size as :attr:`other`.\n",
            " |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
            " |      \n",
            " |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
            " |      \n",
            " |      Args:\n",
            " |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
            " |              as :attr:`other`.\n",
            " |  \n",
            " |  expm1(...)\n",
            " |      expm1() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.expm1`\n",
            " |  \n",
            " |  expm1_(...)\n",
            " |      expm1_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.expm1`\n",
            " |  \n",
            " |  exponential_(...)\n",
            " |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
            " |      \n",
            " |      .. math::\n",
            " |      \n",
            " |          f(x) = \\lambda e^{-\\lambda x}\n",
            " |  \n",
            " |  fill_(...)\n",
            " |      fill_(value) -> Tensor\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with the specified value.\n",
            " |  \n",
            " |  fill_diagonal_(...)\n",
            " |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
            " |      \n",
            " |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
            " |      When dims>2, all dimensions of input must be of equal length.\n",
            " |      This function modifies the input tensor in-place, and returns the input tensor.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          fill_value (Scalar): the fill value\n",
            " |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> a = torch.zeros(3, 3)\n",
            " |          >>> a.fill_diagonal_(5)\n",
            " |          tensor([[5., 0., 0.],\n",
            " |                  [0., 5., 0.],\n",
            " |                  [0., 0., 5.]])\n",
            " |          >>> b = torch.zeros(7, 3)\n",
            " |          >>> b.fill_diagonal_(5)\n",
            " |          tensor([[5., 0., 0.],\n",
            " |                  [0., 5., 0.],\n",
            " |                  [0., 0., 5.],\n",
            " |                  [0., 0., 0.],\n",
            " |                  [0., 0., 0.],\n",
            " |                  [0., 0., 0.],\n",
            " |                  [0., 0., 0.]])\n",
            " |          >>> c = torch.zeros(7, 3)\n",
            " |          >>> c.fill_diagonal_(5, wrap=True)\n",
            " |          tensor([[5., 0., 0.],\n",
            " |                  [0., 5., 0.],\n",
            " |                  [0., 0., 5.],\n",
            " |                  [0., 0., 0.],\n",
            " |                  [5., 0., 0.],\n",
            " |                  [0., 5., 0.],\n",
            " |                  [0., 0., 5.]])\n",
            " |  \n",
            " |  fix(...)\n",
            " |      fix() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.fix`.\n",
            " |  \n",
            " |  fix_(...)\n",
            " |      fix_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.fix`\n",
            " |  \n",
            " |  flatten(...)\n",
            " |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
            " |      \n",
            " |      see :func:`torch.flatten`\n",
            " |  \n",
            " |  flip(...)\n",
            " |      flip(dims) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.flip`\n",
            " |  \n",
            " |  fliplr(...)\n",
            " |      fliplr() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.fliplr`\n",
            " |  \n",
            " |  flipud(...)\n",
            " |      flipud() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.flipud`\n",
            " |  \n",
            " |  float(...)\n",
            " |      float(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  float_power(...)\n",
            " |      float_power(exponent) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.float_power`\n",
            " |  \n",
            " |  float_power_(...)\n",
            " |      float_power_(exponent) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.float_power`\n",
            " |  \n",
            " |  floor(...)\n",
            " |      floor() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.floor`\n",
            " |  \n",
            " |  floor_(...)\n",
            " |      floor_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.floor`\n",
            " |  \n",
            " |  floor_divide(...)\n",
            " |      floor_divide(value) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.floor_divide`\n",
            " |  \n",
            " |  floor_divide_(...)\n",
            " |      floor_divide_(value) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.floor_divide`\n",
            " |  \n",
            " |  fmod(...)\n",
            " |      fmod(divisor) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.fmod`\n",
            " |  \n",
            " |  fmod_(...)\n",
            " |      fmod_(divisor) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.fmod`\n",
            " |  \n",
            " |  frac(...)\n",
            " |      frac() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.frac`\n",
            " |  \n",
            " |  frac_(...)\n",
            " |      frac_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.frac`\n",
            " |  \n",
            " |  gather(...)\n",
            " |      gather(dim, index) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.gather`\n",
            " |  \n",
            " |  gcd(...)\n",
            " |      gcd(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.gcd`\n",
            " |  \n",
            " |  gcd_(...)\n",
            " |      gcd_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.gcd`\n",
            " |  \n",
            " |  ge(...)\n",
            " |      ge(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.ge`.\n",
            " |  \n",
            " |  ge_(...)\n",
            " |      ge_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.ge`.\n",
            " |  \n",
            " |  geometric_(...)\n",
            " |      geometric_(p, *, generator=None) -> Tensor\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
            " |      \n",
            " |      .. math::\n",
            " |      \n",
            " |          f(X=k) = p^{k - 1} (1 - p)\n",
            " |  \n",
            " |  geqrf(...)\n",
            " |      geqrf() -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.geqrf`\n",
            " |  \n",
            " |  ger(...)\n",
            " |      ger(vec2) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.ger`\n",
            " |  \n",
            " |  get_device(...)\n",
            " |      get_device() -> Device ordinal (Integer)\n",
            " |      \n",
            " |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
            " |      For CPU tensors, an error is thrown.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
            " |          >>> x.get_device()\n",
            " |          0\n",
            " |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
            " |  \n",
            " |  greater(...)\n",
            " |      greater(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.greater`.\n",
            " |  \n",
            " |  greater_(...)\n",
            " |      greater_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.greater`.\n",
            " |  \n",
            " |  greater_equal(...)\n",
            " |      greater_equal(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.greater_equal`.\n",
            " |  \n",
            " |  greater_equal_(...)\n",
            " |      greater_equal_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.greater_equal`.\n",
            " |  \n",
            " |  gt(...)\n",
            " |      gt(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.gt`.\n",
            " |  \n",
            " |  gt_(...)\n",
            " |      gt_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.gt`.\n",
            " |  \n",
            " |  half(...)\n",
            " |      half(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  hardshrink(...)\n",
            " |      hardshrink(lambd=0.5) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.nn.functional.hardshrink`\n",
            " |  \n",
            " |  has_names(...)\n",
            " |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
            " |  \n",
            " |  heaviside(...)\n",
            " |      heaviside(values) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.heaviside`\n",
            " |  \n",
            " |  heaviside_(...)\n",
            " |      heaviside_(values) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.heaviside`\n",
            " |  \n",
            " |  histc(...)\n",
            " |      histc(bins=100, min=0, max=0) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.histc`\n",
            " |  \n",
            " |  hypot(...)\n",
            " |      hypot(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.hypot`\n",
            " |  \n",
            " |  hypot_(...)\n",
            " |      hypot_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.hypot`\n",
            " |  \n",
            " |  i0(...)\n",
            " |      i0() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.i0`\n",
            " |  \n",
            " |  i0_(...)\n",
            " |      i0_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.i0`\n",
            " |  \n",
            " |  igamma(...)\n",
            " |      igamma(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.igamma`\n",
            " |  \n",
            " |  igamma_(...)\n",
            " |      igamma_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.igamma`\n",
            " |  \n",
            " |  igammac(...)\n",
            " |      igammac(other) -> Tensor\n",
            " |      See :func:`torch.igammac`\n",
            " |  \n",
            " |  igammac_(...)\n",
            " |      igammac_(other) -> Tensor\n",
            " |      In-place version of :meth:`~Tensor.igammac`\n",
            " |  \n",
            " |  index_add(...)\n",
            " |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
            " |      \n",
            " |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
            " |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
            " |  \n",
            " |  index_add_(...)\n",
            " |      index_add_(dim, index, tensor) -> Tensor\n",
            " |      \n",
            " |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
            " |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
            " |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
            " |      ``j``\\ th row of :attr:`self`.\n",
            " |      \n",
            " |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
            " |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
            " |      match :attr:`self`, or an error will be raised.\n",
            " |      \n",
            " |      Note:\n",
            " |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (int): dimension along which to index\n",
            " |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
            " |          tensor (Tensor): the tensor containing values to add\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.ones(5, 3)\n",
            " |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
            " |          >>> index = torch.tensor([0, 4, 2])\n",
            " |          >>> x.index_add_(0, index, t)\n",
            " |          tensor([[  2.,   3.,   4.],\n",
            " |                  [  1.,   1.,   1.],\n",
            " |                  [  8.,   9.,  10.],\n",
            " |                  [  1.,   1.,   1.],\n",
            " |                  [  5.,   6.,   7.]])\n",
            " |  \n",
            " |  index_copy(...)\n",
            " |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
            " |      \n",
            " |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
            " |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
            " |  \n",
            " |  index_copy_(...)\n",
            " |      index_copy_(dim, index, tensor) -> Tensor\n",
            " |      \n",
            " |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
            " |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
            " |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
            " |      ``j``\\ th row of :attr:`self`.\n",
            " |      \n",
            " |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
            " |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
            " |      match :attr:`self`, or an error will be raised.\n",
            " |      \n",
            " |      .. note::\n",
            " |          If :attr:`index` contains duplicate entries, multiple elements from\n",
            " |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
            " |          is nondeterministic since it depends on which copy occurs last.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (int): dimension along which to index\n",
            " |          index (LongTensor): indices of :attr:`tensor` to select from\n",
            " |          tensor (Tensor): the tensor containing values to copy\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.zeros(5, 3)\n",
            " |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
            " |          >>> index = torch.tensor([0, 4, 2])\n",
            " |          >>> x.index_copy_(0, index, t)\n",
            " |          tensor([[ 1.,  2.,  3.],\n",
            " |                  [ 0.,  0.,  0.],\n",
            " |                  [ 7.,  8.,  9.],\n",
            " |                  [ 0.,  0.,  0.],\n",
            " |                  [ 4.,  5.,  6.]])\n",
            " |  \n",
            " |  index_fill(...)\n",
            " |      index_fill(tensor1, dim, index, value) -> Tensor\n",
            " |      \n",
            " |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
            " |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
            " |  \n",
            " |  index_fill_(...)\n",
            " |      index_fill_(dim, index, val) -> Tensor\n",
            " |      \n",
            " |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
            " |      selecting the indices in the order given in :attr:`index`.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (int): dimension along which to index\n",
            " |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
            " |          val (float): the value to fill with\n",
            " |      \n",
            " |      Example::\n",
            " |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
            " |          >>> index = torch.tensor([0, 2])\n",
            " |          >>> x.index_fill_(1, index, -1)\n",
            " |          tensor([[-1.,  2., -1.],\n",
            " |                  [-1.,  5., -1.],\n",
            " |                  [-1.,  8., -1.]])\n",
            " |  \n",
            " |  index_put(...)\n",
            " |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
            " |      \n",
            " |      Out-place version of :meth:`~Tensor.index_put_`.\n",
            " |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
            " |  \n",
            " |  index_put_(...)\n",
            " |      index_put_(indices, values, accumulate=False) -> Tensor\n",
            " |      \n",
            " |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
            " |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
            " |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
            " |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
            " |      \n",
            " |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
            " |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
            " |      contain duplicate elements.\n",
            " |      \n",
            " |      Args:\n",
            " |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
            " |          values (Tensor): tensor of same dtype as `self`.\n",
            " |          accumulate (bool): whether to accumulate into self\n",
            " |  \n",
            " |  index_select(...)\n",
            " |      index_select(dim, index) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.index_select`\n",
            " |  \n",
            " |  indices(...)\n",
            " |      indices() -> Tensor\n",
            " |      \n",
            " |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
            " |      \n",
            " |      See also :meth:`Tensor.values`.\n",
            " |      \n",
            " |      .. note::\n",
            " |        This method can only be called on a coalesced sparse tensor. See\n",
            " |        :meth:`Tensor.coalesce` for details.\n",
            " |  \n",
            " |  inner(...)\n",
            " |      inner(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.inner`.\n",
            " |  \n",
            " |  int(...)\n",
            " |      int(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  int_repr(...)\n",
            " |      int_repr() -> Tensor\n",
            " |      \n",
            " |      Given a quantized Tensor,\n",
            " |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
            " |      underlying uint8_t values of the given Tensor.\n",
            " |  \n",
            " |  inverse(...)\n",
            " |      inverse() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.inverse`\n",
            " |  \n",
            " |  is_coalesced(...)\n",
            " |      is_coalesced() -> bool\n",
            " |      \n",
            " |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
            " |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
            " |      \n",
            " |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
            " |  \n",
            " |  is_complex(...)\n",
            " |      is_complex() -> bool\n",
            " |      \n",
            " |      Returns True if the data type of :attr:`self` is a complex data type.\n",
            " |  \n",
            " |  is_contiguous(...)\n",
            " |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
            " |      \n",
            " |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
            " |      by memory format.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
            " |              order. Default: ``torch.contiguous_format``.\n",
            " |  \n",
            " |  is_distributed(...)\n",
            " |  \n",
            " |  is_floating_point(...)\n",
            " |      is_floating_point() -> bool\n",
            " |      \n",
            " |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
            " |  \n",
            " |  is_nonzero(...)\n",
            " |  \n",
            " |  is_pinned(...)\n",
            " |      Returns true if this tensor resides in pinned memory.\n",
            " |  \n",
            " |  is_same_size(...)\n",
            " |  \n",
            " |  is_set_to(...)\n",
            " |      is_set_to(tensor) -> bool\n",
            " |      \n",
            " |      Returns True if both tensors are pointing to the exact same memory (same\n",
            " |      storage, offset, size and stride).\n",
            " |  \n",
            " |  is_signed(...)\n",
            " |      is_signed() -> bool\n",
            " |      \n",
            " |      Returns True if the data type of :attr:`self` is a signed data type.\n",
            " |  \n",
            " |  isclose(...)\n",
            " |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.isclose`\n",
            " |  \n",
            " |  isfinite(...)\n",
            " |      isfinite() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.isfinite`\n",
            " |  \n",
            " |  isinf(...)\n",
            " |      isinf() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.isinf`\n",
            " |  \n",
            " |  isnan(...)\n",
            " |      isnan() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.isnan`\n",
            " |  \n",
            " |  isneginf(...)\n",
            " |      isneginf() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.isneginf`\n",
            " |  \n",
            " |  isposinf(...)\n",
            " |      isposinf() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.isposinf`\n",
            " |  \n",
            " |  isreal(...)\n",
            " |      isreal() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.isreal`\n",
            " |  \n",
            " |  item(...)\n",
            " |      item() -> number\n",
            " |      \n",
            " |      Returns the value of this tensor as a standard Python number. This only works\n",
            " |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
            " |      \n",
            " |      This operation is not differentiable.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.tensor([1.0])\n",
            " |          >>> x.item()\n",
            " |          1.0\n",
            " |  \n",
            " |  kron(...)\n",
            " |      kron(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.kron`\n",
            " |  \n",
            " |  kthvalue(...)\n",
            " |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
            " |      \n",
            " |      See :func:`torch.kthvalue`\n",
            " |  \n",
            " |  lcm(...)\n",
            " |      lcm(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.lcm`\n",
            " |  \n",
            " |  lcm_(...)\n",
            " |      lcm_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.lcm`\n",
            " |  \n",
            " |  ldexp(...)\n",
            " |      ldexp(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.ldexp`\n",
            " |  \n",
            " |  ldexp_(...)\n",
            " |      ldexp_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.ldexp`\n",
            " |  \n",
            " |  le(...)\n",
            " |      le(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.le`.\n",
            " |  \n",
            " |  le_(...)\n",
            " |      le_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.le`.\n",
            " |  \n",
            " |  lerp(...)\n",
            " |      lerp(end, weight) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.lerp`\n",
            " |  \n",
            " |  lerp_(...)\n",
            " |      lerp_(end, weight) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.lerp`\n",
            " |  \n",
            " |  less(...)\n",
            " |      lt(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.less`.\n",
            " |  \n",
            " |  less_(...)\n",
            " |      less_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.less`.\n",
            " |  \n",
            " |  less_equal(...)\n",
            " |      less_equal(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.less_equal`.\n",
            " |  \n",
            " |  less_equal_(...)\n",
            " |      less_equal_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.less_equal`.\n",
            " |  \n",
            " |  lgamma(...)\n",
            " |      lgamma() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.lgamma`\n",
            " |  \n",
            " |  lgamma_(...)\n",
            " |      lgamma_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.lgamma`\n",
            " |  \n",
            " |  log(...)\n",
            " |      log() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.log`\n",
            " |  \n",
            " |  log10(...)\n",
            " |      log10() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.log10`\n",
            " |  \n",
            " |  log10_(...)\n",
            " |      log10_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.log10`\n",
            " |  \n",
            " |  log1p(...)\n",
            " |      log1p() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.log1p`\n",
            " |  \n",
            " |  log1p_(...)\n",
            " |      log1p_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.log1p`\n",
            " |  \n",
            " |  log2(...)\n",
            " |      log2() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.log2`\n",
            " |  \n",
            " |  log2_(...)\n",
            " |      log2_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.log2`\n",
            " |  \n",
            " |  log_(...)\n",
            " |      log_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.log`\n",
            " |  \n",
            " |  log_normal_(...)\n",
            " |      log_normal_(mean=1, std=2, *, generator=None)\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
            " |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
            " |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
            " |      standard deviation of the underlying normal distribution, and not of the\n",
            " |      returned distribution:\n",
            " |      \n",
            " |      .. math::\n",
            " |      \n",
            " |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
            " |  \n",
            " |  log_softmax(...)\n",
            " |  \n",
            " |  logaddexp(...)\n",
            " |      logaddexp(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logaddexp`\n",
            " |  \n",
            " |  logaddexp2(...)\n",
            " |      logaddexp2(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logaddexp2`\n",
            " |  \n",
            " |  logcumsumexp(...)\n",
            " |      logcumsumexp(dim) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logcumsumexp`\n",
            " |  \n",
            " |  logdet(...)\n",
            " |      logdet() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logdet`\n",
            " |  \n",
            " |  logical_and(...)\n",
            " |      logical_and() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logical_and`\n",
            " |  \n",
            " |  logical_and_(...)\n",
            " |      logical_and_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.logical_and`\n",
            " |  \n",
            " |  logical_not(...)\n",
            " |      logical_not() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logical_not`\n",
            " |  \n",
            " |  logical_not_(...)\n",
            " |      logical_not_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.logical_not`\n",
            " |  \n",
            " |  logical_or(...)\n",
            " |      logical_or() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logical_or`\n",
            " |  \n",
            " |  logical_or_(...)\n",
            " |      logical_or_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.logical_or`\n",
            " |  \n",
            " |  logical_xor(...)\n",
            " |      logical_xor() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logical_xor`\n",
            " |  \n",
            " |  logical_xor_(...)\n",
            " |      logical_xor_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.logical_xor`\n",
            " |  \n",
            " |  logit(...)\n",
            " |      logit() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logit`\n",
            " |  \n",
            " |  logit_(...)\n",
            " |      logit_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.logit`\n",
            " |  \n",
            " |  logsumexp(...)\n",
            " |      logsumexp(dim, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.logsumexp`\n",
            " |  \n",
            " |  long(...)\n",
            " |      long(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  lstsq(...)\n",
            " |      lstsq(A) -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.lstsq`\n",
            " |  \n",
            " |  lt(...)\n",
            " |      lt(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.lt`.\n",
            " |  \n",
            " |  lt_(...)\n",
            " |      lt_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.lt`.\n",
            " |  \n",
            " |  lu_solve(...)\n",
            " |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.lu_solve`\n",
            " |  \n",
            " |  map2_(...)\n",
            " |  \n",
            " |  map_(...)\n",
            " |      map_(tensor, callable)\n",
            " |      \n",
            " |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
            " |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
            " |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
            " |      \n",
            " |      The :attr:`callable` should have the signature::\n",
            " |      \n",
            " |          def callable(a, b) -> number\n",
            " |  \n",
            " |  masked_fill(...)\n",
            " |      masked_fill(mask, value) -> Tensor\n",
            " |      \n",
            " |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
            " |  \n",
            " |  masked_fill_(...)\n",
            " |      masked_fill_(mask, value)\n",
            " |      \n",
            " |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
            " |      True. The shape of :attr:`mask` must be\n",
            " |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
            " |      tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          mask (BoolTensor): the boolean mask\n",
            " |          value (float): the value to fill in with\n",
            " |  \n",
            " |  masked_scatter(...)\n",
            " |      masked_scatter(mask, tensor) -> Tensor\n",
            " |      \n",
            " |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
            " |  \n",
            " |  masked_scatter_(...)\n",
            " |      masked_scatter_(mask, source)\n",
            " |      \n",
            " |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
            " |      the :attr:`mask` is True.\n",
            " |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
            " |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
            " |      as many elements as the number of ones in :attr:`mask`\n",
            " |      \n",
            " |      Args:\n",
            " |          mask (BoolTensor): the boolean mask\n",
            " |          source (Tensor): the tensor to copy from\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
            " |          :attr:`source` tensor.\n",
            " |  \n",
            " |  masked_select(...)\n",
            " |      masked_select(mask) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.masked_select`\n",
            " |  \n",
            " |  matmul(...)\n",
            " |      matmul(tensor2) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.matmul`\n",
            " |  \n",
            " |  matrix_exp(...)\n",
            " |      matrix_exp() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.matrix_exp`\n",
            " |  \n",
            " |  matrix_power(...)\n",
            " |      matrix_power(n) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.matrix_power`\n",
            " |  \n",
            " |  max(...)\n",
            " |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.max`\n",
            " |  \n",
            " |  maximum(...)\n",
            " |      maximum(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.maximum`\n",
            " |  \n",
            " |  mean(...)\n",
            " |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.mean`\n",
            " |  \n",
            " |  median(...)\n",
            " |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
            " |      \n",
            " |      See :func:`torch.median`\n",
            " |  \n",
            " |  min(...)\n",
            " |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.min`\n",
            " |  \n",
            " |  minimum(...)\n",
            " |      minimum(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.minimum`\n",
            " |  \n",
            " |  mm(...)\n",
            " |      mm(mat2) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.mm`\n",
            " |  \n",
            " |  mode(...)\n",
            " |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
            " |      \n",
            " |      See :func:`torch.mode`\n",
            " |  \n",
            " |  moveaxis(...)\n",
            " |      moveaxis(source, destination) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.moveaxis`\n",
            " |  \n",
            " |  movedim(...)\n",
            " |      movedim(source, destination) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.movedim`\n",
            " |  \n",
            " |  msort(...)\n",
            " |      msort() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.msort`\n",
            " |  \n",
            " |  mul(...)\n",
            " |      mul(value) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.mul`.\n",
            " |  \n",
            " |  mul_(...)\n",
            " |      mul_(value) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.mul`.\n",
            " |  \n",
            " |  multinomial(...)\n",
            " |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.multinomial`\n",
            " |  \n",
            " |  multiply(...)\n",
            " |      multiply(value) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.multiply`.\n",
            " |  \n",
            " |  multiply_(...)\n",
            " |      multiply_(value) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.multiply`.\n",
            " |  \n",
            " |  mv(...)\n",
            " |      mv(vec) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.mv`\n",
            " |  \n",
            " |  mvlgamma(...)\n",
            " |      mvlgamma(p) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.mvlgamma`\n",
            " |  \n",
            " |  mvlgamma_(...)\n",
            " |      mvlgamma_(p) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.mvlgamma`\n",
            " |  \n",
            " |  nan_to_num(...)\n",
            " |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.nan_to_num`.\n",
            " |  \n",
            " |  nan_to_num_(...)\n",
            " |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
            " |  \n",
            " |  nanmedian(...)\n",
            " |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
            " |      \n",
            " |      See :func:`torch.nanmedian`\n",
            " |  \n",
            " |  nanquantile(...)\n",
            " |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.nanquantile`\n",
            " |  \n",
            " |  nansum(...)\n",
            " |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.nansum`\n",
            " |  \n",
            " |  narrow(...)\n",
            " |      narrow(dimension, start, length) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.narrow`\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
            " |          >>> x.narrow(0, 0, 2)\n",
            " |          tensor([[ 1,  2,  3],\n",
            " |                  [ 4,  5,  6]])\n",
            " |          >>> x.narrow(1, 1, 2)\n",
            " |          tensor([[ 2,  3],\n",
            " |                  [ 5,  6],\n",
            " |                  [ 8,  9]])\n",
            " |  \n",
            " |  narrow_copy(...)\n",
            " |      narrow_copy(dimension, start, length) -> Tensor\n",
            " |      \n",
            " |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
            " |      than shared storage.  This is primarily for sparse tensors, which\n",
            " |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
            " |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
            " |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
            " |  \n",
            " |  ndimension(...)\n",
            " |      ndimension() -> int\n",
            " |      \n",
            " |      Alias for :meth:`~Tensor.dim()`\n",
            " |  \n",
            " |  ne(...)\n",
            " |      ne(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.ne`.\n",
            " |  \n",
            " |  ne_(...)\n",
            " |      ne_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.ne`.\n",
            " |  \n",
            " |  neg(...)\n",
            " |      neg() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.neg`\n",
            " |  \n",
            " |  neg_(...)\n",
            " |      neg_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.neg`\n",
            " |  \n",
            " |  negative(...)\n",
            " |      negative() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.negative`\n",
            " |  \n",
            " |  negative_(...)\n",
            " |      negative_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.negative`\n",
            " |  \n",
            " |  nelement(...)\n",
            " |      nelement() -> int\n",
            " |      \n",
            " |      Alias for :meth:`~Tensor.numel`\n",
            " |  \n",
            " |  new(...)\n",
            " |  \n",
            " |  new_empty(...)\n",
            " |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
            " |      \n",
            " |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
            " |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
            " |      :class:`torch.device` as this tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
            " |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
            " |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            " |              Default: if None, same :class:`torch.device` as this tensor.\n",
            " |          requires_grad (bool, optional): If autograd should record operations on the\n",
            " |              returned tensor. Default: ``False``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> tensor = torch.ones(())\n",
            " |          >>> tensor.new_empty((2, 3))\n",
            " |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
            " |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
            " |  \n",
            " |  new_empty_strided(...)\n",
            " |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
            " |      \n",
            " |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
            " |      uninitialized data. By default, the returned Tensor has the same\n",
            " |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
            " |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
            " |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            " |              Default: if None, same :class:`torch.device` as this tensor.\n",
            " |          requires_grad (bool, optional): If autograd should record operations on the\n",
            " |              returned tensor. Default: ``False``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> tensor = torch.ones(())\n",
            " |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
            " |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
            " |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
            " |  \n",
            " |  new_full(...)\n",
            " |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
            " |      \n",
            " |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
            " |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
            " |      :class:`torch.device` as this tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          fill_value (scalar): the number to fill the output tensor with.\n",
            " |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
            " |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
            " |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            " |              Default: if None, same :class:`torch.device` as this tensor.\n",
            " |          requires_grad (bool, optional): If autograd should record operations on the\n",
            " |              returned tensor. Default: ``False``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
            " |          >>> tensor.new_full((3, 4), 3.141592)\n",
            " |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
            " |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
            " |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
            " |  \n",
            " |  new_ones(...)\n",
            " |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
            " |      \n",
            " |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
            " |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
            " |      :class:`torch.device` as this tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
            " |              shape of the output tensor.\n",
            " |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
            " |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
            " |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            " |              Default: if None, same :class:`torch.device` as this tensor.\n",
            " |          requires_grad (bool, optional): If autograd should record operations on the\n",
            " |              returned tensor. Default: ``False``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
            " |          >>> tensor.new_ones((2, 3))\n",
            " |          tensor([[ 1,  1,  1],\n",
            " |                  [ 1,  1,  1]], dtype=torch.int32)\n",
            " |  \n",
            " |  new_tensor(...)\n",
            " |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
            " |      \n",
            " |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
            " |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
            " |      :class:`torch.device` as this tensor.\n",
            " |      \n",
            " |      .. warning::\n",
            " |      \n",
            " |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
            " |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
            " |          or :func:`torch.Tensor.detach`.\n",
            " |          If you have a numpy array and want to avoid a copy, use\n",
            " |          :func:`torch.from_numpy`.\n",
            " |      \n",
            " |      .. warning::\n",
            " |      \n",
            " |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
            " |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
            " |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
            " |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
            " |      \n",
            " |      Args:\n",
            " |          data (array_like): The returned Tensor copies :attr:`data`.\n",
            " |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
            " |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
            " |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            " |              Default: if None, same :class:`torch.device` as this tensor.\n",
            " |          requires_grad (bool, optional): If autograd should record operations on the\n",
            " |              returned tensor. Default: ``False``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
            " |          >>> data = [[0, 1], [2, 3]]\n",
            " |          >>> tensor.new_tensor(data)\n",
            " |          tensor([[ 0,  1],\n",
            " |                  [ 2,  3]], dtype=torch.int8)\n",
            " |  \n",
            " |  new_zeros(...)\n",
            " |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
            " |      \n",
            " |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
            " |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
            " |      :class:`torch.device` as this tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
            " |              shape of the output tensor.\n",
            " |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
            " |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
            " |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            " |              Default: if None, same :class:`torch.device` as this tensor.\n",
            " |          requires_grad (bool, optional): If autograd should record operations on the\n",
            " |              returned tensor. Default: ``False``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
            " |          >>> tensor.new_zeros((2, 3))\n",
            " |          tensor([[ 0.,  0.,  0.],\n",
            " |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
            " |  \n",
            " |  nextafter(...)\n",
            " |      nextafter(other) -> Tensor\n",
            " |      See :func:`torch.nextafter`\n",
            " |  \n",
            " |  nextafter_(...)\n",
            " |      nextafter_(other) -> Tensor\n",
            " |      In-place version of :meth:`~Tensor.nextafter`\n",
            " |  \n",
            " |  nonzero(...)\n",
            " |      nonzero() -> LongTensor\n",
            " |      \n",
            " |      See :func:`torch.nonzero`\n",
            " |  \n",
            " |  normal_(...)\n",
            " |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
            " |      parameterized by :attr:`mean` and :attr:`std`.\n",
            " |  \n",
            " |  not_equal(...)\n",
            " |      not_equal(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.not_equal`.\n",
            " |  \n",
            " |  not_equal_(...)\n",
            " |      not_equal_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.not_equal`.\n",
            " |  \n",
            " |  numel(...)\n",
            " |      numel() -> int\n",
            " |      \n",
            " |      See :func:`torch.numel`\n",
            " |  \n",
            " |  numpy(...)\n",
            " |      numpy() -> numpy.ndarray\n",
            " |      \n",
            " |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
            " |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
            " |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
            " |  \n",
            " |  orgqr(...)\n",
            " |      orgqr(input2) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.orgqr`\n",
            " |  \n",
            " |  ormqr(...)\n",
            " |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.ormqr`\n",
            " |  \n",
            " |  outer(...)\n",
            " |      outer(vec2) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.outer`.\n",
            " |  \n",
            " |  permute(...)\n",
            " |      permute(*dims) -> Tensor\n",
            " |      \n",
            " |      Returns a view of the original tensor with its dimensions permuted.\n",
            " |      \n",
            " |      Args:\n",
            " |          *dims (int...): The desired ordering of dimensions\n",
            " |      \n",
            " |      Example:\n",
            " |          >>> x = torch.randn(2, 3, 5)\n",
            " |          >>> x.size()\n",
            " |          torch.Size([2, 3, 5])\n",
            " |          >>> x.permute(2, 0, 1).size()\n",
            " |          torch.Size([5, 2, 3])\n",
            " |  \n",
            " |  pin_memory(...)\n",
            " |      pin_memory() -> Tensor\n",
            " |      \n",
            " |      Copies the tensor to pinned memory, if it's not already pinned.\n",
            " |  \n",
            " |  pinverse(...)\n",
            " |      pinverse() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.pinverse`\n",
            " |  \n",
            " |  polygamma(...)\n",
            " |      polygamma(n) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.polygamma`\n",
            " |  \n",
            " |  polygamma_(...)\n",
            " |      polygamma_(n) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.polygamma`\n",
            " |  \n",
            " |  pow(...)\n",
            " |      pow(exponent) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.pow`\n",
            " |  \n",
            " |  pow_(...)\n",
            " |      pow_(exponent) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.pow`\n",
            " |  \n",
            " |  prelu(...)\n",
            " |  \n",
            " |  prod(...)\n",
            " |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.prod`\n",
            " |  \n",
            " |  put_(...)\n",
            " |      put_(indices, tensor, accumulate=False) -> Tensor\n",
            " |      \n",
            " |      Copies the elements from :attr:`tensor` into the positions specified by\n",
            " |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
            " |      it were a 1-D tensor.\n",
            " |      \n",
            " |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
            " |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
            " |      contain duplicate elements.\n",
            " |      \n",
            " |      Args:\n",
            " |          indices (LongTensor): the indices into self\n",
            " |          tensor (Tensor): the tensor containing values to copy from\n",
            " |          accumulate (bool): whether to accumulate into self\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> src = torch.tensor([[4, 3, 5],\n",
            " |                                  [6, 7, 8]])\n",
            " |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
            " |          tensor([[  4,   9,   5],\n",
            " |                  [ 10,   7,   8]])\n",
            " |  \n",
            " |  q_per_channel_axis(...)\n",
            " |      q_per_channel_axis() -> int\n",
            " |      \n",
            " |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
            " |      returns the index of dimension on which per-channel quantization is applied.\n",
            " |  \n",
            " |  q_per_channel_scales(...)\n",
            " |      q_per_channel_scales() -> Tensor\n",
            " |      \n",
            " |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
            " |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
            " |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
            " |      the tensor.\n",
            " |  \n",
            " |  q_per_channel_zero_points(...)\n",
            " |      q_per_channel_zero_points() -> Tensor\n",
            " |      \n",
            " |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
            " |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
            " |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
            " |      the tensor.\n",
            " |  \n",
            " |  q_scale(...)\n",
            " |      q_scale() -> float\n",
            " |      \n",
            " |      Given a Tensor quantized by linear(affine) quantization,\n",
            " |      returns the scale of the underlying quantizer().\n",
            " |  \n",
            " |  q_zero_point(...)\n",
            " |      q_zero_point() -> int\n",
            " |      \n",
            " |      Given a Tensor quantized by linear(affine) quantization,\n",
            " |      returns the zero_point of the underlying quantizer().\n",
            " |  \n",
            " |  qr(...)\n",
            " |      qr(some=True) -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.qr`\n",
            " |  \n",
            " |  qscheme(...)\n",
            " |      qscheme() -> torch.qscheme\n",
            " |      \n",
            " |      Returns the quantization scheme of a given QTensor.\n",
            " |  \n",
            " |  quantile(...)\n",
            " |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.quantile`\n",
            " |  \n",
            " |  rad2deg(...)\n",
            " |      rad2deg() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.rad2deg`\n",
            " |  \n",
            " |  rad2deg_(...)\n",
            " |      rad2deg_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.rad2deg`\n",
            " |  \n",
            " |  random_(...)\n",
            " |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
            " |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
            " |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
            " |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
            " |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
            " |      will be uniform in ``[0, 2^53]``.\n",
            " |  \n",
            " |  ravel(...)\n",
            " |      ravel(input) -> Tensor\n",
            " |      \n",
            " |      see :func:`torch.ravel`\n",
            " |  \n",
            " |  reciprocal(...)\n",
            " |      reciprocal() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.reciprocal`\n",
            " |  \n",
            " |  reciprocal_(...)\n",
            " |      reciprocal_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.reciprocal`\n",
            " |  \n",
            " |  record_stream(...)\n",
            " |      record_stream(stream)\n",
            " |      \n",
            " |      Ensures that the tensor memory is not reused for another tensor until all\n",
            " |      current work queued on :attr:`stream` are complete.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          The caching allocator is aware of only the stream where a tensor was\n",
            " |          allocated. Due to the awareness, it already correctly manages the life\n",
            " |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
            " |          different from the stream of origin, the allocator might reuse the memory\n",
            " |          unexpectedly. Calling this method lets the allocator know which streams\n",
            " |          have used the tensor.\n",
            " |  \n",
            " |  relu(...)\n",
            " |  \n",
            " |  relu_(...)\n",
            " |  \n",
            " |  remainder(...)\n",
            " |      remainder(divisor) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.remainder`\n",
            " |  \n",
            " |  remainder_(...)\n",
            " |      remainder_(divisor) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.remainder`\n",
            " |  \n",
            " |  renorm(...)\n",
            " |      renorm(p, dim, maxnorm) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.renorm`\n",
            " |  \n",
            " |  renorm_(...)\n",
            " |      renorm_(p, dim, maxnorm) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.renorm`\n",
            " |  \n",
            " |  repeat(...)\n",
            " |      repeat(*sizes) -> Tensor\n",
            " |      \n",
            " |      Repeats this tensor along the specified dimensions.\n",
            " |      \n",
            " |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
            " |      \n",
            " |      .. warning::\n",
            " |      \n",
            " |          :meth:`~Tensor.repeat` behaves differently from\n",
            " |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
            " |          but is more similar to\n",
            " |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
            " |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
            " |      \n",
            " |      Args:\n",
            " |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
            " |              dimension\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.tensor([1, 2, 3])\n",
            " |          >>> x.repeat(4, 2)\n",
            " |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
            " |                  [ 1,  2,  3,  1,  2,  3],\n",
            " |                  [ 1,  2,  3,  1,  2,  3],\n",
            " |                  [ 1,  2,  3,  1,  2,  3]])\n",
            " |          >>> x.repeat(4, 2, 1).size()\n",
            " |          torch.Size([4, 2, 3])\n",
            " |  \n",
            " |  repeat_interleave(...)\n",
            " |      repeat_interleave(repeats, dim=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.repeat_interleave`.\n",
            " |  \n",
            " |  requires_grad_(...)\n",
            " |      requires_grad_(requires_grad=True) -> Tensor\n",
            " |      \n",
            " |      Change if autograd should record operations on this tensor: sets this tensor's\n",
            " |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
            " |      \n",
            " |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
            " |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
            " |      (because it was obtained through a DataLoader, or required preprocessing or\n",
            " |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
            " |      begin to record operations on ``tensor``.\n",
            " |      \n",
            " |      Args:\n",
            " |          requires_grad (bool): If autograd should record operations on this tensor.\n",
            " |              Default: ``True``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> # Let's say we want to preprocess some saved weights and use\n",
            " |          >>> # the result as new weights.\n",
            " |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
            " |          >>> loaded_weights = torch.tensor(saved_weights)\n",
            " |          >>> weights = preprocess(loaded_weights)  # some function\n",
            " |          >>> weights\n",
            " |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
            " |      \n",
            " |          >>> # Now, start to record operations done to weights\n",
            " |          >>> weights.requires_grad_()\n",
            " |          >>> out = weights.pow(2).sum()\n",
            " |          >>> out.backward()\n",
            " |          >>> weights.grad\n",
            " |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
            " |  \n",
            " |  reshape(...)\n",
            " |      reshape(*shape) -> Tensor\n",
            " |      \n",
            " |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
            " |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
            " |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
            " |      possible to return a view.\n",
            " |      \n",
            " |      See :func:`torch.reshape`\n",
            " |      \n",
            " |      Args:\n",
            " |          shape (tuple of ints or int...): the desired shape\n",
            " |  \n",
            " |  reshape_as(...)\n",
            " |      reshape_as(other) -> Tensor\n",
            " |      \n",
            " |      Returns this tensor as the same shape as :attr:`other`.\n",
            " |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
            " |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
            " |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
            " |      \n",
            " |      Please see :meth:`reshape` for more information about ``reshape``.\n",
            " |      \n",
            " |      Args:\n",
            " |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
            " |              as :attr:`other`.\n",
            " |  \n",
            " |  resize_(...)\n",
            " |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
            " |      \n",
            " |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
            " |      larger than the current storage size, then the underlying storage is resized\n",
            " |      to fit the new number of elements. If the number of elements is smaller, the\n",
            " |      underlying storage is not changed. Existing elements are preserved but any new\n",
            " |      memory is uninitialized.\n",
            " |      \n",
            " |      .. warning::\n",
            " |      \n",
            " |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
            " |          ignoring the current strides (unless the target size equals the current\n",
            " |          size, in which case the tensor is left unchanged). For most purposes, you\n",
            " |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
            " |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
            " |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          sizes (torch.Size or int...): the desired size\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
            " |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
            " |          >>> x.resize_(2, 2)\n",
            " |          tensor([[ 1,  2],\n",
            " |                  [ 3,  4]])\n",
            " |  \n",
            " |  resize_as_(...)\n",
            " |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
            " |      \n",
            " |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
            " |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
            " |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
            " |  \n",
            " |  roll(...)\n",
            " |      roll(shifts, dims) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.roll`\n",
            " |  \n",
            " |  rot90(...)\n",
            " |      rot90(k, dims) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.rot90`\n",
            " |  \n",
            " |  round(...)\n",
            " |      round() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.round`\n",
            " |  \n",
            " |  round_(...)\n",
            " |      round_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.round`\n",
            " |  \n",
            " |  rsqrt(...)\n",
            " |      rsqrt() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.rsqrt`\n",
            " |  \n",
            " |  rsqrt_(...)\n",
            " |      rsqrt_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.rsqrt`\n",
            " |  \n",
            " |  scatter(...)\n",
            " |      scatter(dim, index, src) -> Tensor\n",
            " |      \n",
            " |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
            " |  \n",
            " |  scatter_(...)\n",
            " |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
            " |      \n",
            " |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
            " |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
            " |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
            " |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
            " |      \n",
            " |      For a 3-D tensor, :attr:`self` is updated as::\n",
            " |      \n",
            " |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
            " |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
            " |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
            " |      \n",
            " |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
            " |      \n",
            " |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
            " |      the same number of dimensions. It is also required that\n",
            " |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
            " |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
            " |      Note that ``index`` and ``src`` do not broadcast.\n",
            " |      \n",
            " |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
            " |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
            " |      \n",
            " |      .. warning::\n",
            " |      \n",
            " |          When indices are not unique, the behavior is non-deterministic (one of the\n",
            " |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
            " |          incorrect (it will be propagated to all locations in the source that\n",
            " |          correspond to the same index)!\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
            " |      \n",
            " |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
            " |      specification of an optional reduction operation, which is applied to all\n",
            " |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
            " |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
            " |      operation is applied to an index in :attr:`self` which is specified by\n",
            " |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
            " |      value in :attr:`index` for ``dimension = dim``.\n",
            " |      \n",
            " |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
            " |      is updated as::\n",
            " |      \n",
            " |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
            " |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
            " |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
            " |      \n",
            " |      Reducing with the addition operation is the same as using\n",
            " |      :meth:`~torch.Tensor.scatter_add_`.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (int): the axis along which to index\n",
            " |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
            " |              or of the same dimensionality as ``src``. When empty, the operation\n",
            " |              returns ``self`` unchanged.\n",
            " |          src (Tensor or float): the source element(s) to scatter.\n",
            " |          reduce (str, optional): reduction operation to apply, can be either\n",
            " |              ``'add'`` or ``'multiply'``.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
            " |          >>> src\n",
            " |          tensor([[ 1,  2,  3,  4,  5],\n",
            " |                  [ 6,  7,  8,  9, 10]])\n",
            " |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
            " |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
            " |          tensor([[1, 0, 0, 4, 0],\n",
            " |                  [0, 2, 0, 0, 0],\n",
            " |                  [0, 0, 3, 0, 0]])\n",
            " |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
            " |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
            " |          tensor([[1, 2, 3, 0, 0],\n",
            " |                  [6, 7, 0, 0, 8],\n",
            " |                  [0, 0, 0, 0, 0]])\n",
            " |      \n",
            " |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
            " |          ...            1.23, reduce='multiply')\n",
            " |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
            " |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
            " |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
            " |          ...            1.23, reduce='add')\n",
            " |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
            " |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
            " |  \n",
            " |  scatter_add(...)\n",
            " |      scatter_add(dim, index, src) -> Tensor\n",
            " |      \n",
            " |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
            " |  \n",
            " |  scatter_add_(...)\n",
            " |      scatter_add_(dim, index, src) -> Tensor\n",
            " |      \n",
            " |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
            " |      specified in the :attr:`index` tensor in a similar fashion as\n",
            " |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
            " |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
            " |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
            " |      ``dimension = dim``.\n",
            " |      \n",
            " |      For a 3-D tensor, :attr:`self` is updated as::\n",
            " |      \n",
            " |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
            " |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
            " |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
            " |      \n",
            " |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
            " |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
            " |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
            " |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
            " |      \n",
            " |      Note:\n",
            " |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (int): the axis along which to index\n",
            " |          index (LongTensor): the indices of elements to scatter and add, can be\n",
            " |              either empty or of the same dimensionality as ``src``. When empty, the\n",
            " |              operation returns ``self`` unchanged.\n",
            " |          src (Tensor): the source elements to scatter and add\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> src = torch.ones((2, 5))\n",
            " |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
            " |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
            " |          tensor([[1., 0., 0., 1., 1.],\n",
            " |                  [0., 1., 0., 0., 0.],\n",
            " |                  [0., 0., 1., 0., 0.]])\n",
            " |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
            " |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
            " |          tensor([[2., 0., 0., 1., 1.],\n",
            " |                  [0., 2., 0., 0., 0.],\n",
            " |                  [0., 0., 2., 1., 1.]])\n",
            " |  \n",
            " |  select(...)\n",
            " |      select(dim, index) -> Tensor\n",
            " |      \n",
            " |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
            " |      This function returns a view of the original tensor with the given dimension removed.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (int): the dimension to slice\n",
            " |          index (int): the index to select with\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          :meth:`select` is equivalent to slicing. For example,\n",
            " |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
            " |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
            " |  \n",
            " |  set_(...)\n",
            " |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
            " |      \n",
            " |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
            " |      :attr:`self` tensor will share the same storage and have the same size and\n",
            " |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
            " |      in the other.\n",
            " |      \n",
            " |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
            " |      storage, offset, size, and stride.\n",
            " |      \n",
            " |      Args:\n",
            " |          source (Tensor or Storage): the tensor or storage to use\n",
            " |          storage_offset (int, optional): the offset in the storage\n",
            " |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
            " |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
            " |  \n",
            " |  sgn(...)\n",
            " |      sgn() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sgn`\n",
            " |  \n",
            " |  sgn_(...)\n",
            " |      sgn_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sgn`\n",
            " |  \n",
            " |  short(...)\n",
            " |      short(memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
            " |      \n",
            " |      Args:\n",
            " |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |  \n",
            " |  sigmoid(...)\n",
            " |      sigmoid() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sigmoid`\n",
            " |  \n",
            " |  sigmoid_(...)\n",
            " |      sigmoid_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sigmoid`\n",
            " |  \n",
            " |  sign(...)\n",
            " |      sign() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sign`\n",
            " |  \n",
            " |  sign_(...)\n",
            " |      sign_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sign`\n",
            " |  \n",
            " |  signbit(...)\n",
            " |      signbit() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.signbit`\n",
            " |  \n",
            " |  sin(...)\n",
            " |      sin() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sin`\n",
            " |  \n",
            " |  sin_(...)\n",
            " |      sin_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sin`\n",
            " |  \n",
            " |  sinc(...)\n",
            " |      sinc() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sinc`\n",
            " |  \n",
            " |  sinc_(...)\n",
            " |      sinc_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sinc`\n",
            " |  \n",
            " |  sinh(...)\n",
            " |      sinh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sinh`\n",
            " |  \n",
            " |  sinh_(...)\n",
            " |      sinh_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sinh`\n",
            " |  \n",
            " |  size(...)\n",
            " |      size() -> torch.Size\n",
            " |      \n",
            " |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
            " |      :class:`tuple`.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> torch.empty(3, 4, 5).size()\n",
            " |          torch.Size([3, 4, 5])\n",
            " |  \n",
            " |  slogdet(...)\n",
            " |      slogdet() -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.slogdet`\n",
            " |  \n",
            " |  smm(...)\n",
            " |      smm(mat) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.smm`\n",
            " |  \n",
            " |  softmax(...)\n",
            " |  \n",
            " |  solve(...)\n",
            " |      solve(A) -> Tensor, Tensor\n",
            " |      \n",
            " |      See :func:`torch.solve`\n",
            " |  \n",
            " |  sort(...)\n",
            " |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
            " |      \n",
            " |      See :func:`torch.sort`\n",
            " |  \n",
            " |  sparse_dim(...)\n",
            " |      sparse_dim() -> int\n",
            " |      \n",
            " |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is not a sparse tensor.\n",
            " |      \n",
            " |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
            " |  \n",
            " |  sparse_mask(...)\n",
            " |      sparse_mask(mask) -> Tensor\n",
            " |      \n",
            " |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
            " |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
            " |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
            " |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
            " |      shape.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |        The returned sparse tensor has the same indices as the sparse tensor\n",
            " |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
            " |        zeros.\n",
            " |      \n",
            " |      Args:\n",
            " |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> nse = 5\n",
            " |          >>> dims = (5, 5, 2, 2)\n",
            " |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
            " |                             torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
            " |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
            " |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
            " |          >>> D = torch.randn(dims)\n",
            " |          >>> D.sparse_mask(S)\n",
            " |          tensor(indices=tensor([[0, 0, 0, 2],\n",
            " |                                 [0, 1, 4, 3]]),\n",
            " |                 values=tensor([[[ 1.6550,  0.2397],\n",
            " |                                 [-0.1611, -0.0779]],\n",
            " |      \n",
            " |                                [[ 0.2326, -1.0558],\n",
            " |                                 [ 1.4711,  1.9678]],\n",
            " |      \n",
            " |                                [[-0.5138, -0.0411],\n",
            " |                                 [ 1.9417,  0.5158]],\n",
            " |      \n",
            " |                                [[ 0.0793,  0.0036],\n",
            " |                                 [-0.2569, -0.1055]]]),\n",
            " |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
            " |  \n",
            " |  sparse_resize_(...)\n",
            " |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
            " |      \n",
            " |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
            " |      size and the number of sparse and dense dimensions.\n",
            " |      \n",
            " |      .. note::\n",
            " |        If the number of specified elements in :attr:`self` is zero, then\n",
            " |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
            " |        size and positive integers such that ``len(size) == sparse_dim +\n",
            " |        dense_dim``.\n",
            " |      \n",
            " |        If :attr:`self` specifies one or more elements, however, then each\n",
            " |        dimension in :attr:`size` must not be smaller than the corresponding\n",
            " |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
            " |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
            " |        equal the number of dense dimensions in :attr:`self`.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is not a sparse tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
            " |            sparse tensor, the desired size cannot be smaller than the\n",
            " |            original size.\n",
            " |          sparse_dim (int): the number of sparse dimensions\n",
            " |          dense_dim (int): the number of dense dimensions\n",
            " |  \n",
            " |  sparse_resize_and_clear_(...)\n",
            " |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
            " |      \n",
            " |      Removes all specified elements from a :ref:`sparse tensor\n",
            " |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
            " |      size and the number of sparse and dense dimensions.\n",
            " |      \n",
            " |      .. warning:\n",
            " |        Throws an error if :attr:`self` is not a sparse tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          size (torch.Size): the desired size.\n",
            " |          sparse_dim (int): the number of sparse dimensions\n",
            " |          dense_dim (int): the number of dense dimensions\n",
            " |  \n",
            " |  split_with_sizes(...)\n",
            " |  \n",
            " |  sqrt(...)\n",
            " |      sqrt() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sqrt`\n",
            " |  \n",
            " |  sqrt_(...)\n",
            " |      sqrt_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sqrt`\n",
            " |  \n",
            " |  square(...)\n",
            " |      square() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.square`\n",
            " |  \n",
            " |  square_(...)\n",
            " |      square_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.square`\n",
            " |  \n",
            " |  squeeze(...)\n",
            " |      squeeze(dim=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.squeeze`\n",
            " |  \n",
            " |  squeeze_(...)\n",
            " |      squeeze_(dim=None) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.squeeze`\n",
            " |  \n",
            " |  sspaddmm(...)\n",
            " |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sspaddmm`\n",
            " |  \n",
            " |  std(...)\n",
            " |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.std`\n",
            " |  \n",
            " |  storage(...)\n",
            " |      storage() -> torch.Storage\n",
            " |      \n",
            " |      Returns the underlying storage.\n",
            " |  \n",
            " |  storage_offset(...)\n",
            " |      storage_offset() -> int\n",
            " |      \n",
            " |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
            " |      number of storage elements (not bytes).\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
            " |          >>> x.storage_offset()\n",
            " |          0\n",
            " |          >>> x[3:].storage_offset()\n",
            " |          3\n",
            " |  \n",
            " |  storage_type(...)\n",
            " |      storage_type() -> type\n",
            " |      \n",
            " |      Returns the type of the underlying storage.\n",
            " |  \n",
            " |  stride(...)\n",
            " |      stride(dim) -> tuple or int\n",
            " |      \n",
            " |      Returns the stride of :attr:`self` tensor.\n",
            " |      \n",
            " |      Stride is the jump necessary to go from one element to the next one in the\n",
            " |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
            " |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
            " |      the particular dimension :attr:`dim`.\n",
            " |      \n",
            " |      Args:\n",
            " |          dim (int, optional): the desired dimension in which stride is required\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
            " |          >>> x.stride()\n",
            " |          (5, 1)\n",
            " |          >>>x.stride(0)\n",
            " |          5\n",
            " |          >>> x.stride(-1)\n",
            " |          1\n",
            " |  \n",
            " |  sub(...)\n",
            " |      sub(other, *, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sub`.\n",
            " |  \n",
            " |  sub_(...)\n",
            " |      sub_(other, *, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.sub`\n",
            " |  \n",
            " |  subtract(...)\n",
            " |      subtract(other, *, alpha=1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.subtract`.\n",
            " |  \n",
            " |  subtract_(...)\n",
            " |      subtract_(other, *, alpha=1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.subtract`.\n",
            " |  \n",
            " |  sum(...)\n",
            " |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.sum`\n",
            " |  \n",
            " |  sum_to_size(...)\n",
            " |      sum_to_size(*size) -> Tensor\n",
            " |      \n",
            " |      Sum ``this`` tensor to :attr:`size`.\n",
            " |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
            " |      \n",
            " |      Args:\n",
            " |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
            " |  \n",
            " |  svd(...)\n",
            " |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.svd`\n",
            " |  \n",
            " |  swapaxes(...)\n",
            " |      swapaxes(axis0, axis1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.swapaxes`\n",
            " |  \n",
            " |  swapaxes_(...)\n",
            " |      swapaxes_(axis0, axis1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.swapaxes`\n",
            " |  \n",
            " |  swapdims(...)\n",
            " |      swapdims(dim0, dim1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.swapdims`\n",
            " |  \n",
            " |  swapdims_(...)\n",
            " |      swapdims_(dim0, dim1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.swapdims`\n",
            " |  \n",
            " |  symeig(...)\n",
            " |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.symeig`\n",
            " |  \n",
            " |  t(...)\n",
            " |      t() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.t`\n",
            " |  \n",
            " |  t_(...)\n",
            " |      t_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.t`\n",
            " |  \n",
            " |  take(...)\n",
            " |      take(indices) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.take`\n",
            " |  \n",
            " |  tan(...)\n",
            " |      tan() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.tan`\n",
            " |  \n",
            " |  tan_(...)\n",
            " |      tan_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.tan`\n",
            " |  \n",
            " |  tanh(...)\n",
            " |      tanh() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.tanh`\n",
            " |  \n",
            " |  tanh_(...)\n",
            " |      tanh_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.tanh`\n",
            " |  \n",
            " |  tensor_split(...)\n",
            " |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
            " |      \n",
            " |      See :func:`torch.tensor_split`\n",
            " |  \n",
            " |  tile(...)\n",
            " |      tile(*reps) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.tile`\n",
            " |  \n",
            " |  to(...)\n",
            " |      to(*args, **kwargs) -> Tensor\n",
            " |      \n",
            " |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
            " |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          If the ``self`` Tensor already\n",
            " |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
            " |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
            " |          :class:`torch.dtype` and :class:`torch.device`.\n",
            " |      \n",
            " |      Here are the ways to call ``to``:\n",
            " |      \n",
            " |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |          Returns a Tensor with the specified :attr:`dtype`\n",
            " |      \n",
            " |          Args:\n",
            " |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |      \n",
            " |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
            " |      \n",
            " |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
            " |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
            " |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
            " |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
            " |          CUDA Tensor.\n",
            " |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
            " |          already matches the desired conversion.\n",
            " |      \n",
            " |          Args:\n",
            " |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            " |              returned Tensor. Default: ``torch.preserve_format``.\n",
            " |      \n",
            " |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
            " |      \n",
            " |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
            " |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
            " |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
            " |          Tensor with pinned memory to a CUDA Tensor.\n",
            " |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
            " |          already matches the desired conversion.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
            " |          >>> tensor.to(torch.float64)\n",
            " |          tensor([[-0.5044,  0.0005],\n",
            " |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
            " |      \n",
            " |          >>> cuda0 = torch.device('cuda:0')\n",
            " |          >>> tensor.to(cuda0)\n",
            " |          tensor([[-0.5044,  0.0005],\n",
            " |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
            " |      \n",
            " |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
            " |          tensor([[-0.5044,  0.0005],\n",
            " |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
            " |      \n",
            " |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
            " |          >>> tensor.to(other, non_blocking=True)\n",
            " |          tensor([[-0.5044,  0.0005],\n",
            " |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
            " |  \n",
            " |  to_dense(...)\n",
            " |      to_dense() -> Tensor\n",
            " |      \n",
            " |      Creates a strided copy of :attr:`self`.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is a strided tensor.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> s = torch.sparse_coo_tensor(\n",
            " |                     torch.tensor([[1, 1],\n",
            " |                                   [0, 2]]),\n",
            " |                     torch.tensor([9, 10]),\n",
            " |                     size=(3, 3))\n",
            " |          >>> s.to_dense()\n",
            " |          tensor([[ 0,  0,  0],\n",
            " |                  [ 9,  0, 10],\n",
            " |                  [ 0,  0,  0]])\n",
            " |  \n",
            " |  to_mkldnn(...)\n",
            " |      to_mkldnn() -> Tensor\n",
            " |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
            " |  \n",
            " |  to_sparse(...)\n",
            " |      to_sparse(sparseDims) -> Tensor\n",
            " |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
            " |      :ref:`coordinate format <sparse-coo-docs>`.\n",
            " |      \n",
            " |      Args:\n",
            " |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
            " |          >>> d\n",
            " |          tensor([[ 0,  0,  0],\n",
            " |                  [ 9,  0, 10],\n",
            " |                  [ 0,  0,  0]])\n",
            " |          >>> d.to_sparse()\n",
            " |          tensor(indices=tensor([[1, 1],\n",
            " |                                 [0, 2]]),\n",
            " |                 values=tensor([ 9, 10]),\n",
            " |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
            " |          >>> d.to_sparse(1)\n",
            " |          tensor(indices=tensor([[1]]),\n",
            " |                 values=tensor([[ 9,  0, 10]]),\n",
            " |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
            " |  \n",
            " |  tolist(...)\n",
            " |      tolist() -> list or number\n",
            " |      \n",
            " |      Returns the tensor as a (nested) list. For scalars, a standard\n",
            " |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
            " |      Tensors are automatically moved to the CPU first if necessary.\n",
            " |      \n",
            " |      This operation is not differentiable.\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          >>> a = torch.randn(2, 2)\n",
            " |          >>> a.tolist()\n",
            " |          [[0.012766935862600803, 0.5415473580360413],\n",
            " |           [-0.08909505605697632, 0.7729271650314331]]\n",
            " |          >>> a[0,0].tolist()\n",
            " |          0.012766935862600803\n",
            " |  \n",
            " |  topk(...)\n",
            " |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
            " |      \n",
            " |      See :func:`torch.topk`\n",
            " |  \n",
            " |  trace(...)\n",
            " |      trace() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.trace`\n",
            " |  \n",
            " |  transpose(...)\n",
            " |      transpose(dim0, dim1) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.transpose`\n",
            " |  \n",
            " |  transpose_(...)\n",
            " |      transpose_(dim0, dim1) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.transpose`\n",
            " |  \n",
            " |  triangular_solve(...)\n",
            " |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
            " |      \n",
            " |      See :func:`torch.triangular_solve`\n",
            " |  \n",
            " |  tril(...)\n",
            " |      tril(k=0) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.tril`\n",
            " |  \n",
            " |  tril_(...)\n",
            " |      tril_(k=0) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.tril`\n",
            " |  \n",
            " |  triu(...)\n",
            " |      triu(k=0) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.triu`\n",
            " |  \n",
            " |  triu_(...)\n",
            " |      triu_(k=0) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.triu`\n",
            " |  \n",
            " |  true_divide(...)\n",
            " |      true_divide(value) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.true_divide`\n",
            " |  \n",
            " |  true_divide_(...)\n",
            " |      true_divide_(value) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.true_divide_`\n",
            " |  \n",
            " |  trunc(...)\n",
            " |      trunc() -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.trunc`\n",
            " |  \n",
            " |  trunc_(...)\n",
            " |      trunc_() -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.trunc`\n",
            " |  \n",
            " |  type(...)\n",
            " |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
            " |      Returns the type if `dtype` is not provided, else casts this object to\n",
            " |      the specified type.\n",
            " |      \n",
            " |      If this is already of the correct type, no copy is performed and the\n",
            " |      original object is returned.\n",
            " |      \n",
            " |      Args:\n",
            " |          dtype (type or string): The desired type\n",
            " |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
            " |              and destination is on the GPU or vice versa, the copy is performed\n",
            " |              asynchronously with respect to the host. Otherwise, the argument\n",
            " |              has no effect.\n",
            " |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
            " |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
            " |  \n",
            " |  type_as(...)\n",
            " |      type_as(tensor) -> Tensor\n",
            " |      \n",
            " |      Returns this tensor cast to the type of the given tensor.\n",
            " |      \n",
            " |      This is a no-op if the tensor is already of the correct type. This is\n",
            " |      equivalent to ``self.type(tensor.type())``\n",
            " |      \n",
            " |      Args:\n",
            " |          tensor (Tensor): the tensor which has the desired type\n",
            " |  \n",
            " |  unbind(...)\n",
            " |      unbind(dim=0) -> seq\n",
            " |      \n",
            " |      See :func:`torch.unbind`\n",
            " |  \n",
            " |  unfold(...)\n",
            " |      unfold(dimension, size, step) -> Tensor\n",
            " |      \n",
            " |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
            " |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
            " |      \n",
            " |      Step between two slices is given by :attr:`step`.\n",
            " |      \n",
            " |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
            " |      dimension :attr:`dimension` in the returned tensor will be\n",
            " |      `(sizedim - size) / step + 1`.\n",
            " |      \n",
            " |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          dimension (int): dimension in which unfolding happens\n",
            " |          size (int): the size of each slice that is unfolded\n",
            " |          step (int): the step between each slice\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.arange(1., 8)\n",
            " |          >>> x\n",
            " |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
            " |          >>> x.unfold(0, 2, 1)\n",
            " |          tensor([[ 1.,  2.],\n",
            " |                  [ 2.,  3.],\n",
            " |                  [ 3.,  4.],\n",
            " |                  [ 4.,  5.],\n",
            " |                  [ 5.,  6.],\n",
            " |                  [ 6.,  7.]])\n",
            " |          >>> x.unfold(0, 2, 2)\n",
            " |          tensor([[ 1.,  2.],\n",
            " |                  [ 3.,  4.],\n",
            " |                  [ 5.,  6.]])\n",
            " |  \n",
            " |  uniform_(...)\n",
            " |      uniform_(from=0, to=1) -> Tensor\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
            " |      distribution:\n",
            " |      \n",
            " |      .. math::\n",
            " |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
            " |  \n",
            " |  unsafe_chunk(...)\n",
            " |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
            " |      \n",
            " |      See :func:`torch.unsafe_chunk`\n",
            " |  \n",
            " |  unsafe_split(...)\n",
            " |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
            " |      \n",
            " |      See :func:`torch.unsafe_split`\n",
            " |  \n",
            " |  unsafe_split_with_sizes(...)\n",
            " |  \n",
            " |  unsqueeze(...)\n",
            " |      unsqueeze(dim) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.unsqueeze`\n",
            " |  \n",
            " |  unsqueeze_(...)\n",
            " |      unsqueeze_(dim) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.unsqueeze`\n",
            " |  \n",
            " |  values(...)\n",
            " |      values() -> Tensor\n",
            " |      \n",
            " |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
            " |      \n",
            " |      .. warning::\n",
            " |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
            " |      \n",
            " |      See also :meth:`Tensor.indices`.\n",
            " |      \n",
            " |      .. note::\n",
            " |        This method can only be called on a coalesced sparse tensor. See\n",
            " |        :meth:`Tensor.coalesce` for details.\n",
            " |  \n",
            " |  var(...)\n",
            " |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.var`\n",
            " |  \n",
            " |  vdot(...)\n",
            " |      vdot(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.vdot`\n",
            " |  \n",
            " |  view(...)\n",
            " |      view(*shape) -> Tensor\n",
            " |      \n",
            " |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
            " |      different :attr:`shape`.\n",
            " |      \n",
            " |      The returned tensor shares the same data and must have the same number\n",
            " |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
            " |      view size must be compatible with its original size and stride, i.e., each new\n",
            " |      view dimension must either be a subspace of an original dimension, or only span\n",
            " |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
            " |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
            " |      \n",
            " |      .. math::\n",
            " |      \n",
            " |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
            " |      \n",
            " |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
            " |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
            " |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
            " |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
            " |      :meth:`contiguous`) otherwise.\n",
            " |      \n",
            " |      Args:\n",
            " |          shape (torch.Size or int...): the desired size\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.randn(4, 4)\n",
            " |          >>> x.size()\n",
            " |          torch.Size([4, 4])\n",
            " |          >>> y = x.view(16)\n",
            " |          >>> y.size()\n",
            " |          torch.Size([16])\n",
            " |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
            " |          >>> z.size()\n",
            " |          torch.Size([2, 8])\n",
            " |      \n",
            " |          >>> a = torch.randn(1, 2, 3, 4)\n",
            " |          >>> a.size()\n",
            " |          torch.Size([1, 2, 3, 4])\n",
            " |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
            " |          >>> b.size()\n",
            " |          torch.Size([1, 3, 2, 4])\n",
            " |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
            " |          >>> c.size()\n",
            " |          torch.Size([1, 3, 2, 4])\n",
            " |          >>> torch.equal(b, c)\n",
            " |          False\n",
            " |      \n",
            " |      \n",
            " |      .. function:: view(dtype) -> Tensor\n",
            " |      \n",
            " |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
            " |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
            " |      element as :attr:`self`'s dtype.\n",
            " |      \n",
            " |      .. warning::\n",
            " |      \n",
            " |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
            " |          program will cause undefined behavior.\n",
            " |      \n",
            " |      \n",
            " |      Args:\n",
            " |          dtype (:class:`torch.dtype`): the desired dtype\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> x = torch.randn(4, 4)\n",
            " |          >>> x\n",
            " |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
            " |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
            " |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
            " |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
            " |          >>> x.dtype\n",
            " |          torch.float32\n",
            " |      \n",
            " |          >>> y = x.view(torch.int32)\n",
            " |          >>> y\n",
            " |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
            " |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
            " |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
            " |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
            " |              dtype=torch.int32)\n",
            " |          >>> y[0, 0] = 1000000000\n",
            " |          >>> x\n",
            " |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
            " |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
            " |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
            " |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
            " |      \n",
            " |          >>> x.view(torch.int16)\n",
            " |          Traceback (most recent call last):\n",
            " |            File \"<stdin>\", line 1, in <module>\n",
            " |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
            " |  \n",
            " |  view_as(...)\n",
            " |      view_as(other) -> Tensor\n",
            " |      \n",
            " |      View this tensor as the same size as :attr:`other`.\n",
            " |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
            " |      \n",
            " |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
            " |      \n",
            " |      Args:\n",
            " |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
            " |              as :attr:`other`.\n",
            " |  \n",
            " |  where(...)\n",
            " |      where(condition, y) -> Tensor\n",
            " |      \n",
            " |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
            " |      See :func:`torch.where`\n",
            " |  \n",
            " |  xlogy(...)\n",
            " |      xlogy(other) -> Tensor\n",
            " |      \n",
            " |      See :func:`torch.xlogy`\n",
            " |  \n",
            " |  xlogy_(...)\n",
            " |      xlogy_(other) -> Tensor\n",
            " |      \n",
            " |      In-place version of :meth:`~Tensor.xlogy`\n",
            " |  \n",
            " |  zero_(...)\n",
            " |      zero_() -> Tensor\n",
            " |      \n",
            " |      Fills :attr:`self` tensor with zeros.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from torch._C._TensorBase:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from torch._C._TensorBase:\n",
            " |  \n",
            " |  T\n",
            " |      Is this Tensor with its dimensions reversed.\n",
            " |      \n",
            " |      If ``n`` is the number of dimensions in ``x``,\n",
            " |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
            " |  \n",
            " |  data\n",
            " |  \n",
            " |  device\n",
            " |      Is the :class:`torch.device` where this Tensor is.\n",
            " |  \n",
            " |  dtype\n",
            " |  \n",
            " |  grad_fn\n",
            " |  \n",
            " |  imag\n",
            " |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
            " |      The returned tensor and :attr:`self` share the same underlying storage.\n",
            " |      \n",
            " |      .. warning::\n",
            " |          :func:`imag` is only supported for tensors with complex dtypes.\n",
            " |      \n",
            " |      Example::\n",
            " |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
            " |          >>> x\n",
            " |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
            " |          >>> x.imag\n",
            " |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
            " |  \n",
            " |  is_cuda\n",
            " |      Is ``True`` if the Tensor is stored on the GPU, ``False`` otherwise.\n",
            " |  \n",
            " |  is_leaf\n",
            " |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
            " |      \n",
            " |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
            " |      created by the user. This means that they are not the result of an operation and so\n",
            " |      :attr:`grad_fn` is None.\n",
            " |      \n",
            " |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
            " |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> a = torch.rand(10, requires_grad=True)\n",
            " |          >>> a.is_leaf\n",
            " |          True\n",
            " |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
            " |          >>> b.is_leaf\n",
            " |          False\n",
            " |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
            " |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
            " |          >>> c.is_leaf\n",
            " |          False\n",
            " |          # c was created by the addition operation\n",
            " |          >>> d = torch.rand(10).cuda()\n",
            " |          >>> d.is_leaf\n",
            " |          True\n",
            " |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
            " |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
            " |          >>> e.is_leaf\n",
            " |          True\n",
            " |          # e requires gradients and has no operations creating it\n",
            " |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
            " |          >>> f.is_leaf\n",
            " |          True\n",
            " |          # f requires grad, has no operation creating it\n",
            " |  \n",
            " |  is_meta\n",
            " |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
            " |      are like normal tensors, but they carry no data.\n",
            " |  \n",
            " |  is_mkldnn\n",
            " |  \n",
            " |  is_quantized\n",
            " |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
            " |  \n",
            " |  is_sparse\n",
            " |      Is ``True`` if the Tensor uses sparse storage layout, ``False`` otherwise.\n",
            " |  \n",
            " |  is_vulkan\n",
            " |  \n",
            " |  layout\n",
            " |  \n",
            " |  name\n",
            " |  \n",
            " |  names\n",
            " |      Stores names for each of this tensor's dimensions.\n",
            " |      \n",
            " |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
            " |      Names are either a string if the dimension is named or ``None`` if the\n",
            " |      dimension is unnamed.\n",
            " |      \n",
            " |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
            " |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
            " |      \n",
            " |      Tensors may not have two named dimensions with the same name.\n",
            " |      \n",
            " |      .. warning::\n",
            " |          The named tensor API is experimental and subject to change.\n",
            " |  \n",
            " |  ndim\n",
            " |      Alias for :meth:`~Tensor.dim()`\n",
            " |  \n",
            " |  output_nr\n",
            " |  \n",
            " |  real\n",
            " |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
            " |      The returned tensor and :attr:`self` share the same underlying storage.\n",
            " |      \n",
            " |      .. warning::\n",
            " |          :func:`real` is only supported for tensors with complex dtypes.\n",
            " |      \n",
            " |      Example::\n",
            " |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
            " |          >>> x\n",
            " |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
            " |          >>> x.real\n",
            " |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
            " |  \n",
            " |  requires_grad\n",
            " |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
            " |      \n",
            " |      .. note::\n",
            " |      \n",
            " |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
            " |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
            " |  \n",
            " |  shape\n",
            " |  \n",
            " |  volatile\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00004-629b3dcf-ec17-4e64-b595-771045274367",
        "deepnote_cell_type": "markdown",
        "tags": [],
        "id": "1u6cVtm2kE3u"
      },
      "source": [
        "## 2. Converting Real World Data into Tensors (Image only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00004-dd8ee6ef-bd3d-4fd1-92eb-79e61c6f03cb",
        "deepnote_cell_type": "code",
        "tags": [],
        "id": "2_O4gZVokE3u"
      },
      "source": [
        "### Q2.1. Download the CIFAR-10 Dataset, then create a training set `cifar10` and a validation set `cifar10_val`\n",
        "they should be transformed to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kylTut8GkE3u",
        "colab": {
          "referenced_widgets": [
            "b809901a0b1f49609ac9dd8d4027d8b8"
          ]
        },
        "outputId": "092b615b-597c-4997-cf09-a1339c84c928"
      },
      "source": [
        "data_path = \"./data/\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b809901a0b1f49609ac9dd8d4027d8b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Bk0pwZkE3v"
      },
      "source": [
        "### Q2.2. Stack all images in `cifar10`, checking that the shape of the tensor is (3, 32, 32, 50000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWe9mfxekE3v",
        "outputId": "f270ed55-cab7-4682-d6d6-96606015ce0b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32, 50000])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdT9pOhAkE3v"
      },
      "source": [
        "### Q2.3. Normalize the images by first finding the mean and the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1cdB2pjkE3v",
        "outputId": "cf8ccf70-25f9-4882-ec74-49cae2181f25"
      },
      "source": [
        "# the mean\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBLF6EjIkE3w",
        "outputId": "7d164797-72bf-44b4-db9d-ac8e474a9da3"
      },
      "source": [
        "# the standard deviation\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5E36jSfkE3x"
      },
      "source": [
        "# compose `preprocess`, which stacks both the transforms to tensor and normalization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VTOFj1dkE3x"
      },
      "source": [
        "### Q2.4. Create a normalized dataset `trans_cifar10` and `trans_cifar10_val`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw9QS6NBkE3x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha7QcgUkkE3x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOIjqvUFkE3x"
      },
      "source": [
        "### Q2.5. Create CIFAR-4 (NOT CIFAR-2), leaving behind the following images:\n",
        "- airplanes \n",
        "- automobiles\n",
        "- ships\n",
        "- trucks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGTR18qakE3y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KOMOQrX7kE3y"
      },
      "source": [
        "img_t = cifar4[0][0]\n",
        "img_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHbUgTmpkE3y"
      },
      "source": [
        "### Q2.6. Display any image from cifar4 via pyplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cqDBZwpkE3y"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F0Qj6NSkE3y",
        "outputId": "118ddec8-590f-4837-bda8-5aa3477c0390"
      },
      "source": [
        "plt.imshow(img_t.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00004-4edb3a88-fee0-439c-8ac2-53889e6d7941",
        "deepnote_cell_type": "markdown",
        "tags": [],
        "id": "RMTkho-gkE3y"
      },
      "source": [
        "## 3. Utilizing Pretrained Models (ResNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00005-91d1c16b-b787-43fe-aea8-edf25621b5bd",
        "deepnote_cell_type": "code",
        "tags": [],
        "id": "Cs4kmwsukE3z",
        "colab": {
          "referenced_widgets": [
            "76c3f5dfa8214a32a7a76417176a54fd"
          ]
        },
        "outputId": "77035020-2595-47af-c716-5106218b5fdd"
      },
      "source": [
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76c3f5dfa8214a32a7a76417176a54fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1139055.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG89LQbXkE3z"
      },
      "source": [
        "## Q3.1. Get one single CIFAR-10 image from https://github.com/YoongiKim/CIFAR-10-images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM9JoZQpkE3z"
      },
      "source": [
        "!wget https://github.com/YoongiKim/CIFAR-10-images/blob/master/test/airplane/0001.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "307a2miqkE3z"
      },
      "source": [
        "## Q3.2. Make it into a tensor (you can utilize the transforms that we previously created)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5EazN3qkE3z"
      },
      "source": [
        "from PIL import Image\n",
        "img = Image.open(\"./0000.jpg\")\n",
        "img_t = preprocess(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-x3SrpKkE3z"
      },
      "source": [
        "# Q3.3. Load a pretrained model from https://github.com/chenyaofo/pytorch-cifar-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayOmhTQgkE32"
      },
      "source": [
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoDiZd3akE33"
      },
      "source": [
        "# Q3.4. Evaluate the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0hc-kCxkE33"
      },
      "source": [
        "from torchvision import models\n",
        "resnet = models.resnet101(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00006-1e9f18e0-4954-4d1e-80d6-dceb759f4c25",
        "deepnote_cell_type": "markdown",
        "tags": [],
        "id": "2Ua6jNi2kE33"
      },
      "source": [
        "## Q4. Subclassing `nn.Module` to create Your Own Deep ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00012-22e846c4-386f-4f71-bd31-bbc48ff0ee04",
        "deepnote_cell_type": "code",
        "tags": [],
        "id": "v7-1gSaFkE33"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00012-f2ffc715-6c9c-4d0a-89c8-3d2fcd609df5",
        "deepnote_cell_type": "markdown",
        "tags": [],
        "id": "e2ctV_TRkE33"
      },
      "source": [
        "## HW: Training Your Own Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00017-b40c8539-1bc8-4ce6-865c-f79cce33a5a1",
        "deepnote_cell_type": "code",
        "tags": [],
        "id": "yq6qxBW6kE33"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}